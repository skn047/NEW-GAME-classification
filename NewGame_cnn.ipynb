{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import optuna\n",
    "optuna.logging.disable_default_handler()\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataSet(Dataset):\n",
    "    def __init__(self, csv_path, root_dir):\n",
    "        self.image_dataframe = pd.read_csv(csv_path)\n",
    "        self.root_dir = root_dir\n",
    "        self.images = os.listdir(self.root_dir)\n",
    "        self.transform = transforms.Compose([transforms.ToTensor()])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # 画像読み込み\n",
    "        image_name = self.images[idx]\n",
    "        image = Image.open(os.path.join(self.root_dir, image_name) )\n",
    "        image = image.convert('RGB') # PyTorch 0.4以降\n",
    "        # label (0 or 1)\n",
    "        label = self.image_dataframe.query('ImageName==\"'+image_name+'\"')['ImageLabel'].iloc[0]\n",
    "        return self.transform(image), int(label)\n",
    "\n",
    "imgDataset = MyDataSet('/home/naoki/Documents/newgame.csv', '/home/naoki/Pictures/anime_face/newgame!!/data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(imgDataset, test_size=0.2)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True, num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=64, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.num_workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([15])\n"
     ]
    }
   ],
   "source": [
    "for data, target in train_loader:\n",
    "    print(target.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131    4\n",
       "Name: ImageLabel, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_name = imgDataset.images[8]\n",
    "imgDataset.image_dataframe.query('ImageName==\"'+image_name+'\"')['ImageLabel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageName</th>\n",
       "      <th>ImageLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>32.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>35.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>37.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>45.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>56.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>61.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>66.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>69.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>73.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>75.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>81.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>98.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>107.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>144.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>149.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>157.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>159.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>161.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>164.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>165.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>166.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>170.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>174.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>178.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>3686.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>3687.png</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>3699.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>3703.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>3719.png</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>3733.png</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>3734.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>3741.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>3752.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>3754.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>3759.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>3764.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>3773.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>3795.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>3796.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>3827.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>3830.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>3839.png</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>3889.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>3892.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>3894.png</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>3899.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>3924.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>3936.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>3941.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>3947.png</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>3953.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>3954.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>3956.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>3961.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>499 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ImageName  ImageLabel\n",
       "0       2.png           0\n",
       "1       3.png           1\n",
       "2       4.png           0\n",
       "3       8.png           2\n",
       "4      27.png           0\n",
       "5      30.png           2\n",
       "6      32.png           0\n",
       "7      35.png           0\n",
       "8      37.png           1\n",
       "9      45.png           0\n",
       "10     56.png           0\n",
       "11     61.png           0\n",
       "12     66.png           2\n",
       "13     69.png           2\n",
       "14     73.png           0\n",
       "15     75.png           0\n",
       "16     81.png           0\n",
       "17     98.png           0\n",
       "18    107.png           0\n",
       "19    144.png           0\n",
       "20    149.png           0\n",
       "21    157.png           0\n",
       "22    159.png           0\n",
       "23    161.png           0\n",
       "24    164.png           0\n",
       "25    165.png           1\n",
       "26    166.png           1\n",
       "27    170.png           0\n",
       "28    174.png           1\n",
       "29    178.png           1\n",
       "..        ...         ...\n",
       "469  3686.png           1\n",
       "470  3687.png           5\n",
       "471  3699.png           1\n",
       "472  3703.png           1\n",
       "473  3719.png           5\n",
       "474  3733.png           5\n",
       "475  3734.png           0\n",
       "476  3741.png           0\n",
       "477  3752.png           3\n",
       "478  3754.png           3\n",
       "479  3759.png           0\n",
       "480  3764.png           0\n",
       "481  3773.png           2\n",
       "482  3795.png           0\n",
       "483  3796.png           1\n",
       "484  3827.png           0\n",
       "485  3830.png           0\n",
       "486  3839.png           5\n",
       "487  3889.png           2\n",
       "488  3892.png           0\n",
       "489  3894.png           5\n",
       "490  3899.png           1\n",
       "491  3924.png           0\n",
       "492  3936.png           0\n",
       "493  3941.png           0\n",
       "494  3947.png           5\n",
       "495  3953.png           2\n",
       "496  3954.png           0\n",
       "497  3956.png           2\n",
       "498  3961.png           2\n",
       "\n",
       "[499 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgDataset.image_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 10\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, trial):\n",
    "        super(Net, self).__init__()\n",
    "        self.activation = get_activation(trial)\n",
    "        # self.activation = trial.suggest_categorical('activation', [F.relu, F.elu])\n",
    "        self.conv1 = nn.Conv2d(3, 30, kernel_size=5)  #  64*64*3 -> 60*60*30\n",
    "        self.conv2 = nn.Conv2d(30, 60, kernel_size=5)  #  30*30*30 -> 26*26*60\n",
    "        self.conv2_drop = nn.Dropout2d(p=trial.suggest_uniform(\"dropout_prob\", 0, 0.8))  #  0〜0.8の間でサンプリング\n",
    "        self.fc1 = nn.Linear(13*13*60, 150)\n",
    "        self.fc2 = nn.Linear(150, 6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = self.activation(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 13*13*60)\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "def train(model, device, train_loader, optimizer):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():  #  計算グラフを作らない\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    return 1 - correct / len(test_loader.dataset)\n",
    "\n",
    "def get_optimizer(trial, model):\n",
    "    optimizer_names = ['Adam', 'MomentumSGD']\n",
    "    optimizer_name = trial.suggest_categorical('optimizer', optimizer_names)\n",
    "    weight_decay = trial.suggest_loguniform('weight_decay', 1e-10, 1e-3)\n",
    "    if optimizer_name == optimizer_names[0]: \n",
    "        adam_lr = trial.suggest_loguniform('adam_lr', 1e-5, 1e-1)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=adam_lr, weight_decay=weight_decay)\n",
    "    else:\n",
    "        momentum_sgd_lr = trial.suggest_loguniform('momentum_sgd_lr', 1e-5, 1e-1)\n",
    "        optimizer = optim.SGD(model.parameters(), lr=momentum_sgd_lr,\n",
    "                              momentum=0.9, weight_decay=weight_decay)\n",
    "    return optimizer\n",
    "\n",
    "# def adam(model, trial, weight_decay):\n",
    "#     adam_lr = trial.suggest_loguniform('adam_lr', 1e-5, 1e-1)\n",
    "#     return optim.Adam(model.parameters(), lr=adam_lr, weight_decay=weight_decay)\n",
    "    \n",
    "# def momentum(model, trial, weight_decay):\n",
    "#     momentum_sgd_lr = trial.suggest_loguniform('momentum_sgd_lr', 1e-5, 1e-1)\n",
    "#     return optim.SGD(model.parameters(), lr=momentum_sgd_lr,\n",
    "#                      momentum=0.9, weight_decay=weight_decay)\n",
    "\n",
    "# def get_optimizer(trial, model):\n",
    "#     optimizer = trial.suggest_categorical('optimizer', [adam, momentum])\n",
    "#     weight_decay = trial.suggest_loguniform('weight_decay', 1e-10, 1e-3)\n",
    "#     return optimizer(model, trial, weight_decay)\n",
    "\n",
    "def get_activation(trial):\n",
    "    activation_names = ['ReLU', 'ELU']\n",
    "    activation_name = trial.suggest_categorical('activation', activation_names)\n",
    "    if activation_name == activation_names[0]:\n",
    "        activation = F.relu\n",
    "    else:\n",
    "        activation = F.elu\n",
    "    return activation\n",
    "\n",
    "def objective_wrapper(pbar):\n",
    "    def objective(trial):  #  optunaを使う場合にはtrialを引数にする必要あり\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "        model = Net(trial).to(device)\n",
    "        optimizer = get_optimizer(trial, model)\n",
    "\n",
    "        for step in range(EPOCH):\n",
    "            train(model, device, train_loader, optimizer)\n",
    "            error_rate = test(model, device, test_loader)\n",
    "\n",
    "            trial.report(error_rate, step)\n",
    "            if trial.should_prune(step):\n",
    "                pbar.update()\n",
    "                raise optuna.structs.TrialPruned()\n",
    "\n",
    "        pbar.update()\n",
    "\n",
    "        return error_rate\n",
    "    \n",
    "    return objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c97d579f0d954156b7e9fd6811fac935",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting trial status as TrialState.FAIL because of the following error: RuntimeError('size mismatch, m1: [64 x 10140], m2: [1014 x 150] at /opt/conda/conda-bld/pytorch_1525909934016/work/aten/src/THC/generic/THCTensorMathBlas.cu:249',)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/optuna/study.py\", line 400, in _run_trial\n",
      "    result = func(trial)\n",
      "  File \"<ipython-input-9-5f9f04741407>\", line 89, in objective\n",
      "    train(model, device, train_loader, optimizer)\n",
      "  File \"<ipython-input-9-5f9f04741407>\", line 28, in train\n",
      "    output = model(data)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-9-5f9f04741407>\", line 18, in forward\n",
      "    x = self.activation(self.fc1(x))\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/modules/linear.py\", line 55, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/functional.py\", line 992, in linear\n",
      "    return torch.addmm(bias, input, weight.t())\n",
      "RuntimeError: size mismatch, m1: [64 x 10140], m2: [1014 x 150] at /opt/conda/conda-bld/pytorch_1525909934016/work/aten/src/THC/generic/THCTensorMathBlas.cu:249\n",
      "Setting trial status as TrialState.FAIL because of the following error: RuntimeError('size mismatch, m1: [64 x 10140], m2: [1014 x 150] at /opt/conda/conda-bld/pytorch_1525909934016/work/aten/src/THC/generic/THCTensorMathBlas.cu:249',)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/optuna/study.py\", line 400, in _run_trial\n",
      "    result = func(trial)\n",
      "  File \"<ipython-input-9-5f9f04741407>\", line 89, in objective\n",
      "    train(model, device, train_loader, optimizer)\n",
      "  File \"<ipython-input-9-5f9f04741407>\", line 28, in train\n",
      "    output = model(data)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-9-5f9f04741407>\", line 18, in forward\n",
      "    x = self.activation(self.fc1(x))\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/modules/linear.py\", line 55, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/functional.py\", line 992, in linear\n",
      "    return torch.addmm(bias, input, weight.t())\n",
      "RuntimeError: size mismatch, m1: [64 x 10140], m2: [1014 x 150] at /opt/conda/conda-bld/pytorch_1525909934016/work/aten/src/THC/generic/THCTensorMathBlas.cu:249\n",
      "Setting trial status as TrialState.FAIL because of the following error: RuntimeError('size mismatch, m1: [64 x 10140], m2: [1014 x 150] at /opt/conda/conda-bld/pytorch_1525909934016/work/aten/src/THC/generic/THCTensorMathBlas.cu:249',)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/optuna/study.py\", line 400, in _run_trial\n",
      "    result = func(trial)\n",
      "  File \"<ipython-input-9-5f9f04741407>\", line 89, in objective\n",
      "    train(model, device, train_loader, optimizer)\n",
      "  File \"<ipython-input-9-5f9f04741407>\", line 28, in train\n",
      "    output = model(data)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-9-5f9f04741407>\", line 18, in forward\n",
      "    x = self.activation(self.fc1(x))\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/modules/linear.py\", line 55, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/functional.py\", line 992, in linear\n",
      "    return torch.addmm(bias, input, weight.t())\n",
      "RuntimeError: size mismatch, m1: [64 x 10140], m2: [1014 x 150] at /opt/conda/conda-bld/pytorch_1525909934016/work/aten/src/THC/generic/THCTensorMathBlas.cu:249\n",
      "Setting trial status as TrialState.FAIL because of the following error: RuntimeError('size mismatch, m1: [64 x 10140], m2: [1014 x 150] at /opt/conda/conda-bld/pytorch_1525909934016/work/aten/src/THC/generic/THCTensorMathBlas.cu:249',)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/optuna/study.py\", line 400, in _run_trial\n",
      "    result = func(trial)\n",
      "  File \"<ipython-input-9-5f9f04741407>\", line 89, in objective\n",
      "    train(model, device, train_loader, optimizer)\n",
      "  File \"<ipython-input-9-5f9f04741407>\", line 28, in train\n",
      "    output = model(data)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-9-5f9f04741407>\", line 18, in forward\n",
      "    x = self.activation(self.fc1(x))\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/modules/linear.py\", line 55, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/functional.py\", line 992, in linear\n",
      "    return torch.addmm(bias, input, weight.t())\n",
      "RuntimeError: size mismatch, m1: [64 x 10140], m2: [1014 x 150] at /opt/conda/conda-bld/pytorch_1525909934016/work/aten/src/THC/generic/THCTensorMathBlas.cu:249\n",
      "Setting trial status as TrialState.FAIL because of the following error: RuntimeError('size mismatch, m1: [64 x 10140], m2: [1014 x 150] at /opt/conda/conda-bld/pytorch_1525909934016/work/aten/src/THC/generic/THCTensorMathBlas.cu:249',)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/optuna/study.py\", line 400, in _run_trial\n",
      "    result = func(trial)\n",
      "  File \"<ipython-input-9-5f9f04741407>\", line 89, in objective\n",
      "    train(model, device, train_loader, optimizer)\n",
      "  File \"<ipython-input-9-5f9f04741407>\", line 28, in train\n",
      "    output = model(data)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-9-5f9f04741407>\", line 18, in forward\n",
      "    x = self.activation(self.fc1(x))\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/modules/linear.py\", line 55, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/functional.py\", line 992, in linear\n",
      "    return torch.addmm(bias, input, weight.t())\n",
      "RuntimeError: size mismatch, m1: [64 x 10140], m2: [1014 x 150] at /opt/conda/conda-bld/pytorch_1525909934016/work/aten/src/THC/generic/THCTensorMathBlas.cu:249\n",
      "Setting trial status as TrialState.FAIL because of the following error: RuntimeError('size mismatch, m1: [64 x 10140], m2: [1014 x 150] at /opt/conda/conda-bld/pytorch_1525909934016/work/aten/src/THC/generic/THCTensorMathBlas.cu:249',)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/optuna/study.py\", line 400, in _run_trial\n",
      "    result = func(trial)\n",
      "  File \"<ipython-input-9-5f9f04741407>\", line 89, in objective\n",
      "    train(model, device, train_loader, optimizer)\n",
      "  File \"<ipython-input-9-5f9f04741407>\", line 28, in train\n",
      "    output = model(data)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-9-5f9f04741407>\", line 18, in forward\n",
      "    x = self.activation(self.fc1(x))\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/modules/linear.py\", line 55, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/functional.py\", line 992, in linear\n",
      "    return torch.addmm(bias, input, weight.t())\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RuntimeError: size mismatch, m1: [64 x 10140], m2: [1014 x 150] at /opt/conda/conda-bld/pytorch_1525909934016/work/aten/src/THC/generic/THCTensorMathBlas.cu:249\n",
      "Setting trial status as TrialState.FAIL because of the following error: RuntimeError('size mismatch, m1: [64 x 10140], m2: [1014 x 150] at /opt/conda/conda-bld/pytorch_1525909934016/work/aten/src/THC/generic/THCTensorMathBlas.cu:249',)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/optuna/study.py\", line 400, in _run_trial\n",
      "    result = func(trial)\n",
      "  File \"<ipython-input-9-5f9f04741407>\", line 89, in objective\n",
      "    train(model, device, train_loader, optimizer)\n",
      "  File \"<ipython-input-9-5f9f04741407>\", line 28, in train\n",
      "    output = model(data)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-9-5f9f04741407>\", line 18, in forward\n",
      "    x = self.activation(self.fc1(x))\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/modules/linear.py\", line 55, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/functional.py\", line 992, in linear\n",
      "    return torch.addmm(bias, input, weight.t())\n",
      "RuntimeError: size mismatch, m1: [64 x 10140], m2: [1014 x 150] at /opt/conda/conda-bld/pytorch_1525909934016/work/aten/src/THC/generic/THCTensorMathBlas.cu:249\n",
      "Setting trial status as TrialState.FAIL because of the following error: RuntimeError('size mismatch, m1: [64 x 10140], m2: [1014 x 150] at /opt/conda/conda-bld/pytorch_1525909934016/work/aten/src/THC/generic/THCTensorMathBlas.cu:249',)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/optuna/study.py\", line 400, in _run_trial\n",
      "    result = func(trial)\n",
      "  File \"<ipython-input-9-5f9f04741407>\", line 89, in objective\n",
      "    train(model, device, train_loader, optimizer)\n",
      "  File \"<ipython-input-9-5f9f04741407>\", line 28, in train\n",
      "    output = model(data)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-9-5f9f04741407>\", line 18, in forward\n",
      "    x = self.activation(self.fc1(x))\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/modules/linear.py\", line 55, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/functional.py\", line 992, in linear\n",
      "    return torch.addmm(bias, input, weight.t())\n",
      "RuntimeError: size mismatch, m1: [64 x 10140], m2: [1014 x 150] at /opt/conda/conda-bld/pytorch_1525909934016/work/aten/src/THC/generic/THCTensorMathBlas.cu:249\n",
      "Setting trial status as TrialState.FAIL because of the following error: RuntimeError('size mismatch, m1: [64 x 10140], m2: [1014 x 150] at /opt/conda/conda-bld/pytorch_1525909934016/work/aten/src/THC/generic/THCTensorMathBlas.cu:249',)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/optuna/study.py\", line 400, in _run_trial\n",
      "    result = func(trial)\n",
      "  File \"<ipython-input-9-5f9f04741407>\", line 89, in objective\n",
      "    train(model, device, train_loader, optimizer)\n",
      "  File \"<ipython-input-9-5f9f04741407>\", line 28, in train\n",
      "    output = model(data)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-9-5f9f04741407>\", line 18, in forward\n",
      "    x = self.activation(self.fc1(x))\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/modules/linear.py\", line 55, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/functional.py\", line 992, in linear\n",
      "    return torch.addmm(bias, input, weight.t())\n",
      "RuntimeError: size mismatch, m1: [64 x 10140], m2: [1014 x 150] at /opt/conda/conda-bld/pytorch_1525909934016/work/aten/src/THC/generic/THCTensorMathBlas.cu:249\n",
      "Setting trial status as TrialState.FAIL because of the following error: RuntimeError('size mismatch, m1: [64 x 10140], m2: [1014 x 150] at /opt/conda/conda-bld/pytorch_1525909934016/work/aten/src/THC/generic/THCTensorMathBlas.cu:249',)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/optuna/study.py\", line 400, in _run_trial\n",
      "    result = func(trial)\n",
      "  File \"<ipython-input-9-5f9f04741407>\", line 89, in objective\n",
      "    train(model, device, train_loader, optimizer)\n",
      "  File \"<ipython-input-9-5f9f04741407>\", line 28, in train\n",
      "    output = model(data)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-9-5f9f04741407>\", line 18, in forward\n",
      "    x = self.activation(self.fc1(x))\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/modules/linear.py\", line 55, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/functional.py\", line 992, in linear\n",
      "    return torch.addmm(bias, input, weight.t())\n",
      "RuntimeError: size mismatch, m1: [64 x 10140], m2: [1014 x 150] at /opt/conda/conda-bld/pytorch_1525909934016/work/aten/src/THC/generic/THCTensorMathBlas.cu:249\n",
      "Setting trial status as TrialState.FAIL because of the following error: RuntimeError('size mismatch, m1: [64 x 10140], m2: [1014 x 150] at /opt/conda/conda-bld/pytorch_1525909934016/work/aten/src/THC/generic/THCTensorMathBlas.cu:249',)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/optuna/study.py\", line 400, in _run_trial\n",
      "    result = func(trial)\n",
      "  File \"<ipython-input-9-5f9f04741407>\", line 89, in objective\n",
      "    train(model, device, train_loader, optimizer)\n",
      "  File \"<ipython-input-9-5f9f04741407>\", line 28, in train\n",
      "    output = model(data)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-9-5f9f04741407>\", line 18, in forward\n",
      "    x = self.activation(self.fc1(x))\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/modules/linear.py\", line 55, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/functional.py\", line 992, in linear\n",
      "    return torch.addmm(bias, input, weight.t())\n",
      "RuntimeError: size mismatch, m1: [64 x 10140], m2: [1014 x 150] at /opt/conda/conda-bld/pytorch_1525909934016/work/aten/src/THC/generic/THCTensorMathBlas.cu:249\n",
      "Setting trial status as TrialState.FAIL because of the following error: RuntimeError('size mismatch, m1: [64 x 10140], m2: [1014 x 150] at /opt/conda/conda-bld/pytorch_1525909934016/work/aten/src/THC/generic/THCTensorMathBlas.cu:249',)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/optuna/study.py\", line 400, in _run_trial\n",
      "    result = func(trial)\n",
      "  File \"<ipython-input-9-5f9f04741407>\", line 89, in objective\n",
      "    train(model, device, train_loader, optimizer)\n",
      "  File \"<ipython-input-9-5f9f04741407>\", line 28, in train\n",
      "    output = model(data)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-9-5f9f04741407>\", line 18, in forward\n",
      "    x = self.activation(self.fc1(x))\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/modules/linear.py\", line 55, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/functional.py\", line 992, in linear\n",
      "    return torch.addmm(bias, input, weight.t())\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RuntimeError: size mismatch, m1: [64 x 10140], m2: [1014 x 150] at /opt/conda/conda-bld/pytorch_1525909934016/work/aten/src/THC/generic/THCTensorMathBlas.cu:249\n",
      "Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x7f3e1cdcec18>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 349, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 328, in _shutdown_workers\n",
      "    self.worker_result_queue.get()\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/multiprocessing/reductions.py\", line 70, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/multiprocessing/resource_sharer.py\", line 87, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/multiprocessing/connection.py\", line 494, in Client\n",
      "    deliver_challenge(c, authkey)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/multiprocessing/connection.py\", line 722, in deliver_challenge\n",
      "    response = connection.recv_bytes(256)        # reject large message\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "Setting trial status as TrialState.FAIL because of the following error: RuntimeError('size mismatch, m1: [64 x 10140], m2: [1014 x 150] at /opt/conda/conda-bld/pytorch_1525909934016/work/aten/src/THC/generic/THCTensorMathBlas.cu:249',)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/optuna/study.py\", line 400, in _run_trial\n",
      "    result = func(trial)\n",
      "  File \"<ipython-input-9-5f9f04741407>\", line 89, in objective\n",
      "    train(model, device, train_loader, optimizer)\n",
      "  File \"<ipython-input-9-5f9f04741407>\", line 28, in train\n",
      "    output = model(data)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-9-5f9f04741407>\", line 18, in forward\n",
      "    x = self.activation(self.fc1(x))\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/modules/linear.py\", line 55, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/functional.py\", line 992, in linear\n",
      "    return torch.addmm(bias, input, weight.t())\n",
      "RuntimeError: size mismatch, m1: [64 x 10140], m2: [1014 x 150] at /opt/conda/conda-bld/pytorch_1525909934016/work/aten/src/THC/generic/THCTensorMathBlas.cu:249\n",
      "Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x7f3e1cdcafd0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 349, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 328, in _shutdown_workers\n",
      "    self.worker_result_queue.get()\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/multiprocessing/reductions.py\", line 70, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/multiprocessing/resource_sharer.py\", line 87, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/multiprocessing/connection.py\", line 493, in Client\n",
      "    answer_challenge(c, authkey)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/multiprocessing/connection.py\", line 732, in answer_challenge\n",
      "    message = connection.recv_bytes(256)         # reject large message\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/multiprocessing/connection.py\", line 383, in _recv\n",
      "    raise EOFError\n",
      "EOFError: \n",
      "Setting trial status as TrialState.FAIL because of the following error: RuntimeError('size mismatch, m1: [64 x 10140], m2: [1014 x 150] at /opt/conda/conda-bld/pytorch_1525909934016/work/aten/src/THC/generic/THCTensorMathBlas.cu:249',)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/optuna/study.py\", line 400, in _run_trial\n",
      "    result = func(trial)\n",
      "  File \"<ipython-input-9-5f9f04741407>\", line 89, in objective\n",
      "    train(model, device, train_loader, optimizer)\n",
      "  File \"<ipython-input-9-5f9f04741407>\", line 28, in train\n",
      "    output = model(data)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-9-5f9f04741407>\", line 18, in forward\n",
      "    x = self.activation(self.fc1(x))\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/modules/linear.py\", line 55, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/functional.py\", line 992, in linear\n",
      "    return torch.addmm(bias, input, weight.t())\n",
      "RuntimeError: size mismatch, m1: [64 x 10140], m2: [1014 x 150] at /opt/conda/conda-bld/pytorch_1525909934016/work/aten/src/THC/generic/THCTensorMathBlas.cu:249\n",
      "Setting trial status as TrialState.FAIL because of the following error: RuntimeError('size mismatch, m1: [64 x 10140], m2: [1014 x 150] at /opt/conda/conda-bld/pytorch_1525909934016/work/aten/src/THC/generic/THCTensorMathBlas.cu:249',)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/optuna/study.py\", line 400, in _run_trial\n",
      "    result = func(trial)\n",
      "  File \"<ipython-input-9-5f9f04741407>\", line 89, in objective\n",
      "    train(model, device, train_loader, optimizer)\n",
      "  File \"<ipython-input-9-5f9f04741407>\", line 28, in train\n",
      "    output = model(data)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-9-5f9f04741407>\", line 18, in forward\n",
      "    x = self.activation(self.fc1(x))\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/modules/linear.py\", line 55, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/functional.py\", line 992, in linear\n",
      "    return torch.addmm(bias, input, weight.t())\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RuntimeError: size mismatch, m1: [64 x 10140], m2: [1014 x 150] at /opt/conda/conda-bld/pytorch_1525909934016/work/aten/src/THC/generic/THCTensorMathBlas.cu:249\n",
      "Setting trial status as TrialState.FAIL because of the following error: RuntimeError('size mismatch, m1: [64 x 10140], m2: [1014 x 150] at /opt/conda/conda-bld/pytorch_1525909934016/work/aten/src/THC/generic/THCTensorMathBlas.cu:249',)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/optuna/study.py\", line 400, in _run_trial\n",
      "    result = func(trial)\n",
      "  File \"<ipython-input-9-5f9f04741407>\", line 89, in objective\n",
      "    train(model, device, train_loader, optimizer)\n",
      "  File \"<ipython-input-9-5f9f04741407>\", line 28, in train\n",
      "    output = model(data)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-9-5f9f04741407>\", line 18, in forward\n",
      "    x = self.activation(self.fc1(x))\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/modules/linear.py\", line 55, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/functional.py\", line 992, in linear\n",
      "    return torch.addmm(bias, input, weight.t())\n",
      "RuntimeError: size mismatch, m1: [64 x 10140], m2: [1014 x 150] at /opt/conda/conda-bld/pytorch_1525909934016/work/aten/src/THC/generic/THCTensorMathBlas.cu:249\n",
      "Setting trial status as TrialState.FAIL because of the following error: RuntimeError('size mismatch, m1: [64 x 10140], m2: [1014 x 150] at /opt/conda/conda-bld/pytorch_1525909934016/work/aten/src/THC/generic/THCTensorMathBlas.cu:249',)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/optuna/study.py\", line 400, in _run_trial\n",
      "    result = func(trial)\n",
      "  File \"<ipython-input-9-5f9f04741407>\", line 89, in objective\n",
      "    train(model, device, train_loader, optimizer)\n",
      "  File \"<ipython-input-9-5f9f04741407>\", line 28, in train\n",
      "    output = model(data)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-9-5f9f04741407>\", line 18, in forward\n",
      "    x = self.activation(self.fc1(x))\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/modules/linear.py\", line 55, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/functional.py\", line 992, in linear\n",
      "    return torch.addmm(bias, input, weight.t())\n",
      "RuntimeError: size mismatch, m1: [64 x 10140], m2: [1014 x 150] at /opt/conda/conda-bld/pytorch_1525909934016/work/aten/src/THC/generic/THCTensorMathBlas.cu:249\n",
      "Setting trial status as TrialState.FAIL because of the following error: RuntimeError('size mismatch, m1: [64 x 10140], m2: [1014 x 150] at /opt/conda/conda-bld/pytorch_1525909934016/work/aten/src/THC/generic/THCTensorMathBlas.cu:249',)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/optuna/study.py\", line 400, in _run_trial\n",
      "    result = func(trial)\n",
      "  File \"<ipython-input-9-5f9f04741407>\", line 89, in objective\n",
      "    train(model, device, train_loader, optimizer)\n",
      "  File \"<ipython-input-9-5f9f04741407>\", line 28, in train\n",
      "    output = model(data)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-9-5f9f04741407>\", line 18, in forward\n",
      "    x = self.activation(self.fc1(x))\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/modules/linear.py\", line 55, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/functional.py\", line 992, in linear\n",
      "    return torch.addmm(bias, input, weight.t())\n",
      "RuntimeError: size mismatch, m1: [64 x 10140], m2: [1014 x 150] at /opt/conda/conda-bld/pytorch_1525909934016/work/aten/src/THC/generic/THCTensorMathBlas.cu:249\n",
      "Setting trial status as TrialState.FAIL because of the following error: RuntimeError('size mismatch, m1: [64 x 10140], m2: [1014 x 150] at /opt/conda/conda-bld/pytorch_1525909934016/work/aten/src/THC/generic/THCTensorMathBlas.cu:249',)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/optuna/study.py\", line 400, in _run_trial\n",
      "    result = func(trial)\n",
      "  File \"<ipython-input-9-5f9f04741407>\", line 89, in objective\n",
      "    train(model, device, train_loader, optimizer)\n",
      "  File \"<ipython-input-9-5f9f04741407>\", line 28, in train\n",
      "    output = model(data)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-9-5f9f04741407>\", line 18, in forward\n",
      "    x = self.activation(self.fc1(x))\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/modules/linear.py\", line 55, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/functional.py\", line 992, in linear\n",
      "    return torch.addmm(bias, input, weight.t())\n",
      "RuntimeError: size mismatch, m1: [64 x 10140], m2: [1014 x 150] at /opt/conda/conda-bld/pytorch_1525909934016/work/aten/src/THC/generic/THCTensorMathBlas.cu:249\n",
      "Setting trial status as TrialState.FAIL because of the following error: RuntimeError('size mismatch, m1: [64 x 10140], m2: [1014 x 150] at /opt/conda/conda-bld/pytorch_1525909934016/work/aten/src/THC/generic/THCTensorMathBlas.cu:249',)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/optuna/study.py\", line 400, in _run_trial\n",
      "    result = func(trial)\n",
      "  File \"<ipython-input-9-5f9f04741407>\", line 89, in objective\n",
      "    train(model, device, train_loader, optimizer)\n",
      "  File \"<ipython-input-9-5f9f04741407>\", line 28, in train\n",
      "    output = model(data)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-9-5f9f04741407>\", line 18, in forward\n",
      "    x = self.activation(self.fc1(x))\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/modules/linear.py\", line 55, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/nn/functional.py\", line 992, in linear\n",
      "    return torch.addmm(bias, input, weight.t())\n",
      "RuntimeError: size mismatch, m1: [64 x 10140], m2: [1014 x 150] at /opt/conda/conda-bld/pytorch_1525909934016/work/aten/src/THC/generic/THCTensorMathBlas.cu:249\n",
      "Process Process-82:\n",
      "Process Process-81:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-3fe7ada03ba9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTRIAL_SIZE\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpruner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpruners\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMedianPruner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#  インスタンス生成\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTRIAL_SIZE\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#  最適化　目的関数の返り値が小さくなるようにパラメータ探索　-> objective : 誤り率\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#  studyでtrialの処理が行われる\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/optuna/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimize_sequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimize_parallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/optuna/study.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(self, func, n_trials, timeout, catch)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m     def _optimize_parallel(\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/optuna/study.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(self, func, catch)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mstructs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             message = 'Setting trial status as {}. {}'.format(\n",
      "\u001b[0;32m<ipython-input-9-5f9f04741407>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0merror_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-5f9f04741407>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_DataLoaderIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m                 \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdaemon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# ensure that the worker exits on process exit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m                 \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0m_update_worker_pids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/multiprocessing/process.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    103\u001b[0m                \u001b[0;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpopen_fork\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mclass\u001b[0m \u001b[0mSpawnProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseProcess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flush_std_streams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_launch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mduplicate_for_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m_launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mparent_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "TRIAL_SIZE = 100\n",
    "with tqdm(total=TRIAL_SIZE) as pbar:\n",
    "    study = optuna.create_study(pruner=optuna.pruners.MedianPruner())  #  インスタンス生成\n",
    "    study.optimize(objective_wrapper(pbar), n_trials=TRIAL_SIZE)  #  最適化　目的関数の返り値が小さくなるようにパラメータ探索　-> objective : 誤り率\n",
    "\n",
    "#  studyでtrialの処理が行われる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenTrial(trial_id=15, state=<TrialState.COMPLETE: 1>, value=0.040000000000000036, datetime_start=datetime.datetime(2019, 1, 5, 14, 0, 40, 410531), datetime_complete=datetime.datetime(2019, 1, 5, 14, 0, 43, 66237), params={'activation': 'ELU', 'dropout_prob': 0.345478067932839, 'optimizer': 'Adam', 'weight_decay': 1.4248031080514087e-06, 'adam_lr': 0.0002900399340813237}, user_attrs={}, system_attrs={}, intermediate_values={0: 0.6799999999999999, 1: 0.4, 2: 0.17000000000000004, 3: 0.040000000000000036, 4: 0.06999999999999995, 5: 0.050000000000000044, 6: 0.10999999999999999, 7: 0.050000000000000044, 8: 0.050000000000000044, 9: 0.040000000000000036}, params_in_internal_repr={'activation': 1, 'dropout_prob': 0.345478067932839, 'optimizer': 0, 'weight_decay': 1.4248031080514087e-06, 'adam_lr': 0.0002900399340813237})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naoki/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py:87: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/399 (0%)]\tLoss: 1.804325\n",
      "Train Epoch: 1 [64/399 (14%)]\tLoss: 1.818276\n",
      "Train Epoch: 1 [128/399 (29%)]\tLoss: 1.643928\n",
      "Train Epoch: 1 [192/399 (43%)]\tLoss: 1.587973\n",
      "Train Epoch: 1 [256/399 (57%)]\tLoss: 1.517244\n",
      "Train Epoch: 1 [320/399 (71%)]\tLoss: 1.656107\n",
      "Train Epoch: 1 [90/399 (86%)]\tLoss: 1.770938\n",
      "\n",
      "Test set: Average loss: 0.6600, Accuracy: 34/100 (34%)\n",
      "\n",
      "Train Epoch: 2 [0/399 (0%)]\tLoss: 1.509064\n",
      "Train Epoch: 2 [64/399 (14%)]\tLoss: 1.487850\n",
      "Train Epoch: 2 [128/399 (29%)]\tLoss: 1.416274\n",
      "Train Epoch: 2 [192/399 (43%)]\tLoss: 1.343437\n",
      "Train Epoch: 2 [256/399 (57%)]\tLoss: 1.343033\n",
      "Train Epoch: 2 [320/399 (71%)]\tLoss: 1.230462\n",
      "Train Epoch: 2 [90/399 (86%)]\tLoss: 1.296121\n",
      "\n",
      "Test set: Average loss: 0.5300, Accuracy: 47/100 (47%)\n",
      "\n",
      "Train Epoch: 3 [0/399 (0%)]\tLoss: 1.166622\n",
      "Train Epoch: 3 [64/399 (14%)]\tLoss: 1.205175\n",
      "Train Epoch: 3 [128/399 (29%)]\tLoss: 1.040114\n",
      "Train Epoch: 3 [192/399 (43%)]\tLoss: 1.081881\n",
      "Train Epoch: 3 [256/399 (57%)]\tLoss: 1.066868\n",
      "Train Epoch: 3 [320/399 (71%)]\tLoss: 1.034050\n",
      "Train Epoch: 3 [90/399 (86%)]\tLoss: 0.861979\n",
      "\n",
      "Test set: Average loss: 0.3800, Accuracy: 62/100 (62%)\n",
      "\n",
      "Train Epoch: 4 [0/399 (0%)]\tLoss: 1.003960\n",
      "Train Epoch: 4 [64/399 (14%)]\tLoss: 0.818388\n",
      "Train Epoch: 4 [128/399 (29%)]\tLoss: 0.762436\n",
      "Train Epoch: 4 [192/399 (43%)]\tLoss: 0.771420\n",
      "Train Epoch: 4 [256/399 (57%)]\tLoss: 0.801142\n",
      "Train Epoch: 4 [320/399 (71%)]\tLoss: 0.639802\n",
      "Train Epoch: 4 [90/399 (86%)]\tLoss: 0.681809\n",
      "\n",
      "Test set: Average loss: 0.1200, Accuracy: 88/100 (88%)\n",
      "\n",
      "Train Epoch: 5 [0/399 (0%)]\tLoss: 0.624695\n",
      "Train Epoch: 5 [64/399 (14%)]\tLoss: 0.544224\n",
      "Train Epoch: 5 [128/399 (29%)]\tLoss: 0.525142\n",
      "Train Epoch: 5 [192/399 (43%)]\tLoss: 0.526810\n",
      "Train Epoch: 5 [256/399 (57%)]\tLoss: 0.526693\n",
      "Train Epoch: 5 [320/399 (71%)]\tLoss: 0.550184\n",
      "Train Epoch: 5 [90/399 (86%)]\tLoss: 0.490549\n",
      "\n",
      "Test set: Average loss: 0.2200, Accuracy: 78/100 (78%)\n",
      "\n",
      "Train Epoch: 6 [0/399 (0%)]\tLoss: 0.455662\n",
      "Train Epoch: 6 [64/399 (14%)]\tLoss: 0.492408\n",
      "Train Epoch: 6 [128/399 (29%)]\tLoss: 0.396996\n",
      "Train Epoch: 6 [192/399 (43%)]\tLoss: 0.398629\n",
      "Train Epoch: 6 [256/399 (57%)]\tLoss: 0.316259\n",
      "Train Epoch: 6 [320/399 (71%)]\tLoss: 0.318464\n",
      "Train Epoch: 6 [90/399 (86%)]\tLoss: 0.287972\n",
      "\n",
      "Test set: Average loss: 0.1100, Accuracy: 89/100 (89%)\n",
      "\n",
      "Train Epoch: 7 [0/399 (0%)]\tLoss: 0.346994\n",
      "Train Epoch: 7 [64/399 (14%)]\tLoss: 0.323306\n",
      "Train Epoch: 7 [128/399 (29%)]\tLoss: 0.255130\n",
      "Train Epoch: 7 [192/399 (43%)]\tLoss: 0.327958\n",
      "Train Epoch: 7 [256/399 (57%)]\tLoss: 0.237727\n",
      "Train Epoch: 7 [320/399 (71%)]\tLoss: 0.295847\n",
      "Train Epoch: 7 [90/399 (86%)]\tLoss: 0.349312\n",
      "\n",
      "Test set: Average loss: 0.0700, Accuracy: 93/100 (93%)\n",
      "\n",
      "Train Epoch: 8 [0/399 (0%)]\tLoss: 0.236333\n",
      "Train Epoch: 8 [64/399 (14%)]\tLoss: 0.217628\n",
      "Train Epoch: 8 [128/399 (29%)]\tLoss: 0.167912\n",
      "Train Epoch: 8 [192/399 (43%)]\tLoss: 0.207021\n",
      "Train Epoch: 8 [256/399 (57%)]\tLoss: 0.243864\n",
      "Train Epoch: 8 [320/399 (71%)]\tLoss: 0.243723\n",
      "Train Epoch: 8 [90/399 (86%)]\tLoss: 0.159946\n",
      "\n",
      "Test set: Average loss: 0.0700, Accuracy: 93/100 (93%)\n",
      "\n",
      "Train Epoch: 9 [0/399 (0%)]\tLoss: 0.126519\n",
      "Train Epoch: 9 [64/399 (14%)]\tLoss: 0.251543\n",
      "Train Epoch: 9 [128/399 (29%)]\tLoss: 0.144671\n",
      "Train Epoch: 9 [192/399 (43%)]\tLoss: 0.243512\n",
      "Train Epoch: 9 [256/399 (57%)]\tLoss: 0.190922\n",
      "Train Epoch: 9 [320/399 (71%)]\tLoss: 0.232701\n",
      "Train Epoch: 9 [90/399 (86%)]\tLoss: 0.166019\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 96/100 (96%)\n",
      "\n",
      "Train Epoch: 10 [0/399 (0%)]\tLoss: 0.157795\n",
      "Train Epoch: 10 [64/399 (14%)]\tLoss: 0.166966\n",
      "Train Epoch: 10 [128/399 (29%)]\tLoss: 0.162961\n",
      "Train Epoch: 10 [192/399 (43%)]\tLoss: 0.131783\n",
      "Train Epoch: 10 [256/399 (57%)]\tLoss: 0.205347\n",
      "Train Epoch: 10 [320/399 (71%)]\tLoss: 0.132478\n",
      "Train Epoch: 10 [90/399 (86%)]\tLoss: 0.120268\n",
      "\n",
      "Test set: Average loss: 0.0500, Accuracy: 95/100 (95%)\n",
      "\n",
      "Train Epoch: 11 [0/399 (0%)]\tLoss: 0.111641\n",
      "Train Epoch: 11 [64/399 (14%)]\tLoss: 0.244365\n",
      "Train Epoch: 11 [128/399 (29%)]\tLoss: 0.080635\n",
      "Train Epoch: 11 [192/399 (43%)]\tLoss: 0.119156\n",
      "Train Epoch: 11 [256/399 (57%)]\tLoss: 0.189762\n",
      "Train Epoch: 11 [320/399 (71%)]\tLoss: 0.125335\n",
      "Train Epoch: 11 [90/399 (86%)]\tLoss: 0.051325\n",
      "\n",
      "Test set: Average loss: 0.0700, Accuracy: 93/100 (93%)\n",
      "\n",
      "Train Epoch: 12 [0/399 (0%)]\tLoss: 0.106053\n",
      "Train Epoch: 12 [64/399 (14%)]\tLoss: 0.087210\n",
      "Train Epoch: 12 [128/399 (29%)]\tLoss: 0.113054\n",
      "Train Epoch: 12 [192/399 (43%)]\tLoss: 0.074673\n",
      "Train Epoch: 12 [256/399 (57%)]\tLoss: 0.164974\n",
      "Train Epoch: 12 [320/399 (71%)]\tLoss: 0.101450\n",
      "Train Epoch: 12 [90/399 (86%)]\tLoss: 0.248908\n",
      "\n",
      "Test set: Average loss: 0.0600, Accuracy: 94/100 (94%)\n",
      "\n",
      "Train Epoch: 13 [0/399 (0%)]\tLoss: 0.113088\n",
      "Train Epoch: 13 [64/399 (14%)]\tLoss: 0.221551\n",
      "Train Epoch: 13 [128/399 (29%)]\tLoss: 0.171832\n",
      "Train Epoch: 13 [192/399 (43%)]\tLoss: 0.079566\n",
      "Train Epoch: 13 [256/399 (57%)]\tLoss: 0.054696\n",
      "Train Epoch: 13 [320/399 (71%)]\tLoss: 0.099058\n",
      "Train Epoch: 13 [90/399 (86%)]\tLoss: 0.202970\n",
      "\n",
      "Test set: Average loss: 0.0700, Accuracy: 93/100 (93%)\n",
      "\n",
      "Train Epoch: 14 [0/399 (0%)]\tLoss: 0.088153\n",
      "Train Epoch: 14 [64/399 (14%)]\tLoss: 0.134237\n",
      "Train Epoch: 14 [128/399 (29%)]\tLoss: 0.054581\n",
      "Train Epoch: 14 [192/399 (43%)]\tLoss: 0.080738\n",
      "Train Epoch: 14 [256/399 (57%)]\tLoss: 0.061582\n",
      "Train Epoch: 14 [320/399 (71%)]\tLoss: 0.069847\n",
      "Train Epoch: 14 [90/399 (86%)]\tLoss: 0.135232\n",
      "\n",
      "Test set: Average loss: 0.0700, Accuracy: 93/100 (93%)\n",
      "\n",
      "Train Epoch: 15 [0/399 (0%)]\tLoss: 0.088282\n",
      "Train Epoch: 15 [64/399 (14%)]\tLoss: 0.082383\n",
      "Train Epoch: 15 [128/399 (29%)]\tLoss: 0.115156\n",
      "Train Epoch: 15 [192/399 (43%)]\tLoss: 0.051388\n",
      "Train Epoch: 15 [256/399 (57%)]\tLoss: 0.091365\n",
      "Train Epoch: 15 [320/399 (71%)]\tLoss: 0.156650\n",
      "Train Epoch: 15 [90/399 (86%)]\tLoss: 0.033441\n",
      "\n",
      "Test set: Average loss: 0.0600, Accuracy: 94/100 (94%)\n",
      "\n",
      "Train Epoch: 16 [0/399 (0%)]\tLoss: 0.099345\n",
      "Train Epoch: 16 [64/399 (14%)]\tLoss: 0.152081\n",
      "Train Epoch: 16 [128/399 (29%)]\tLoss: 0.029204\n",
      "Train Epoch: 16 [192/399 (43%)]\tLoss: 0.043456\n",
      "Train Epoch: 16 [256/399 (57%)]\tLoss: 0.079852\n",
      "Train Epoch: 16 [320/399 (71%)]\tLoss: 0.048141\n",
      "Train Epoch: 16 [90/399 (86%)]\tLoss: 0.040782\n",
      "\n",
      "Test set: Average loss: 0.0600, Accuracy: 94/100 (94%)\n",
      "\n",
      "Train Epoch: 17 [0/399 (0%)]\tLoss: 0.056228\n",
      "Train Epoch: 17 [64/399 (14%)]\tLoss: 0.061190\n",
      "Train Epoch: 17 [128/399 (29%)]\tLoss: 0.037151\n",
      "Train Epoch: 17 [192/399 (43%)]\tLoss: 0.045458\n",
      "Train Epoch: 17 [256/399 (57%)]\tLoss: 0.049650\n",
      "Train Epoch: 17 [320/399 (71%)]\tLoss: 0.136051\n",
      "Train Epoch: 17 [90/399 (86%)]\tLoss: 0.012409\n",
      "\n",
      "Test set: Average loss: 0.0600, Accuracy: 94/100 (94%)\n",
      "\n",
      "Train Epoch: 18 [0/399 (0%)]\tLoss: 0.044942\n",
      "Train Epoch: 18 [64/399 (14%)]\tLoss: 0.110029\n",
      "Train Epoch: 18 [128/399 (29%)]\tLoss: 0.039048\n",
      "Train Epoch: 18 [192/399 (43%)]\tLoss: 0.036066\n",
      "Train Epoch: 18 [256/399 (57%)]\tLoss: 0.034289\n",
      "Train Epoch: 18 [320/399 (71%)]\tLoss: 0.073439\n",
      "Train Epoch: 18 [90/399 (86%)]\tLoss: 0.008559\n",
      "\n",
      "Test set: Average loss: 0.0600, Accuracy: 94/100 (94%)\n",
      "\n",
      "Train Epoch: 19 [0/399 (0%)]\tLoss: 0.027041\n",
      "Train Epoch: 19 [64/399 (14%)]\tLoss: 0.142583\n",
      "Train Epoch: 19 [128/399 (29%)]\tLoss: 0.089275\n",
      "Train Epoch: 19 [192/399 (43%)]\tLoss: 0.028889\n",
      "Train Epoch: 19 [256/399 (57%)]\tLoss: 0.047363\n",
      "Train Epoch: 19 [320/399 (71%)]\tLoss: 0.030867\n",
      "Train Epoch: 19 [90/399 (86%)]\tLoss: 0.043382\n",
      "\n",
      "Test set: Average loss: 0.0600, Accuracy: 94/100 (94%)\n",
      "\n",
      "Train Epoch: 20 [0/399 (0%)]\tLoss: 0.048701\n",
      "Train Epoch: 20 [64/399 (14%)]\tLoss: 0.014710\n",
      "Train Epoch: 20 [128/399 (29%)]\tLoss: 0.045051\n",
      "Train Epoch: 20 [192/399 (43%)]\tLoss: 0.030643\n",
      "Train Epoch: 20 [256/399 (57%)]\tLoss: 0.067409\n",
      "Train Epoch: 20 [320/399 (71%)]\tLoss: 0.069790\n",
      "Train Epoch: 20 [90/399 (86%)]\tLoss: 0.040652\n",
      "\n",
      "Test set: Average loss: 0.0500, Accuracy: 95/100 (95%)\n",
      "\n",
      "Train Epoch: 21 [0/399 (0%)]\tLoss: 0.038882\n",
      "Train Epoch: 21 [64/399 (14%)]\tLoss: 0.030296\n",
      "Train Epoch: 21 [128/399 (29%)]\tLoss: 0.109904\n",
      "Train Epoch: 21 [192/399 (43%)]\tLoss: 0.043653\n",
      "Train Epoch: 21 [256/399 (57%)]\tLoss: 0.030289\n",
      "Train Epoch: 21 [320/399 (71%)]\tLoss: 0.037855\n",
      "Train Epoch: 21 [90/399 (86%)]\tLoss: 0.023276\n",
      "\n",
      "Test set: Average loss: 0.0500, Accuracy: 95/100 (95%)\n",
      "\n",
      "Train Epoch: 22 [0/399 (0%)]\tLoss: 0.026843\n",
      "Train Epoch: 22 [64/399 (14%)]\tLoss: 0.044458\n",
      "Train Epoch: 22 [128/399 (29%)]\tLoss: 0.025783\n",
      "Train Epoch: 22 [192/399 (43%)]\tLoss: 0.092295\n",
      "Train Epoch: 22 [256/399 (57%)]\tLoss: 0.033564\n",
      "Train Epoch: 22 [320/399 (71%)]\tLoss: 0.059241\n",
      "Train Epoch: 22 [90/399 (86%)]\tLoss: 0.011981\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 96/100 (96%)\n",
      "\n",
      "Train Epoch: 23 [0/399 (0%)]\tLoss: 0.043870\n",
      "Train Epoch: 23 [64/399 (14%)]\tLoss: 0.028949\n",
      "Train Epoch: 23 [128/399 (29%)]\tLoss: 0.023144\n",
      "Train Epoch: 23 [192/399 (43%)]\tLoss: 0.038988\n",
      "Train Epoch: 23 [256/399 (57%)]\tLoss: 0.045025\n",
      "Train Epoch: 23 [320/399 (71%)]\tLoss: 0.024512\n",
      "Train Epoch: 23 [90/399 (86%)]\tLoss: 0.010575\n",
      "\n",
      "Test set: Average loss: 0.0500, Accuracy: 95/100 (95%)\n",
      "\n",
      "Train Epoch: 24 [0/399 (0%)]\tLoss: 0.021163\n",
      "Train Epoch: 24 [64/399 (14%)]\tLoss: 0.034684\n",
      "Train Epoch: 24 [128/399 (29%)]\tLoss: 0.023107\n",
      "Train Epoch: 24 [192/399 (43%)]\tLoss: 0.030639\n",
      "Train Epoch: 24 [256/399 (57%)]\tLoss: 0.053123\n",
      "Train Epoch: 24 [320/399 (71%)]\tLoss: 0.052661\n",
      "Train Epoch: 24 [90/399 (86%)]\tLoss: 0.030833\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 96/100 (96%)\n",
      "\n",
      "Train Epoch: 25 [0/399 (0%)]\tLoss: 0.021894\n",
      "Train Epoch: 25 [64/399 (14%)]\tLoss: 0.024579\n",
      "Train Epoch: 25 [128/399 (29%)]\tLoss: 0.078781\n",
      "Train Epoch: 25 [192/399 (43%)]\tLoss: 0.016481\n",
      "Train Epoch: 25 [256/399 (57%)]\tLoss: 0.029888\n",
      "Train Epoch: 25 [320/399 (71%)]\tLoss: 0.011305\n",
      "Train Epoch: 25 [90/399 (86%)]\tLoss: 0.045763\n",
      "\n",
      "Test set: Average loss: 0.0500, Accuracy: 95/100 (95%)\n",
      "\n",
      "Train Epoch: 26 [0/399 (0%)]\tLoss: 0.026507\n",
      "Train Epoch: 26 [64/399 (14%)]\tLoss: 0.051110\n",
      "Train Epoch: 26 [128/399 (29%)]\tLoss: 0.015422\n",
      "Train Epoch: 26 [192/399 (43%)]\tLoss: 0.019887\n",
      "Train Epoch: 26 [256/399 (57%)]\tLoss: 0.037918\n",
      "Train Epoch: 26 [320/399 (71%)]\tLoss: 0.027910\n",
      "Train Epoch: 26 [90/399 (86%)]\tLoss: 0.018635\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 96/100 (96%)\n",
      "\n",
      "Train Epoch: 27 [0/399 (0%)]\tLoss: 0.039335\n",
      "Train Epoch: 27 [64/399 (14%)]\tLoss: 0.043474\n",
      "Train Epoch: 27 [128/399 (29%)]\tLoss: 0.012708\n",
      "Train Epoch: 27 [192/399 (43%)]\tLoss: 0.021153\n",
      "Train Epoch: 27 [256/399 (57%)]\tLoss: 0.025973\n",
      "Train Epoch: 27 [320/399 (71%)]\tLoss: 0.019380\n",
      "Train Epoch: 27 [90/399 (86%)]\tLoss: 0.017054\n",
      "\n",
      "Test set: Average loss: 0.0500, Accuracy: 95/100 (95%)\n",
      "\n",
      "Train Epoch: 28 [0/399 (0%)]\tLoss: 0.021085\n",
      "Train Epoch: 28 [64/399 (14%)]\tLoss: 0.028966\n",
      "Train Epoch: 28 [128/399 (29%)]\tLoss: 0.025267\n",
      "Train Epoch: 28 [192/399 (43%)]\tLoss: 0.015865\n",
      "Train Epoch: 28 [256/399 (57%)]\tLoss: 0.051163\n",
      "Train Epoch: 28 [320/399 (71%)]\tLoss: 0.026195\n",
      "Train Epoch: 28 [90/399 (86%)]\tLoss: 0.056865\n",
      "\n",
      "Test set: Average loss: 0.0500, Accuracy: 95/100 (95%)\n",
      "\n",
      "Train Epoch: 29 [0/399 (0%)]\tLoss: 0.031823\n",
      "Train Epoch: 29 [64/399 (14%)]\tLoss: 0.024261\n",
      "Train Epoch: 29 [128/399 (29%)]\tLoss: 0.024460\n",
      "Train Epoch: 29 [192/399 (43%)]\tLoss: 0.024634\n",
      "Train Epoch: 29 [256/399 (57%)]\tLoss: 0.011348\n",
      "Train Epoch: 29 [320/399 (71%)]\tLoss: 0.032369\n",
      "Train Epoch: 29 [90/399 (86%)]\tLoss: 0.004635\n",
      "\n",
      "Test set: Average loss: 0.0500, Accuracy: 95/100 (95%)\n",
      "\n",
      "Train Epoch: 30 [0/399 (0%)]\tLoss: 0.019724\n",
      "Train Epoch: 30 [64/399 (14%)]\tLoss: 0.013818\n",
      "Train Epoch: 30 [128/399 (29%)]\tLoss: 0.034151\n",
      "Train Epoch: 30 [192/399 (43%)]\tLoss: 0.022696\n",
      "Train Epoch: 30 [256/399 (57%)]\tLoss: 0.019464\n",
      "Train Epoch: 30 [320/399 (71%)]\tLoss: 0.017578\n",
      "Train Epoch: 30 [90/399 (86%)]\tLoss: 0.083848\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 96/100 (96%)\n",
      "\n",
      "Train Epoch: 31 [0/399 (0%)]\tLoss: 0.012028\n",
      "Train Epoch: 31 [64/399 (14%)]\tLoss: 0.029474\n",
      "Train Epoch: 31 [128/399 (29%)]\tLoss: 0.011560\n",
      "Train Epoch: 31 [192/399 (43%)]\tLoss: 0.013103\n",
      "Train Epoch: 31 [256/399 (57%)]\tLoss: 0.023166\n",
      "Train Epoch: 31 [320/399 (71%)]\tLoss: 0.015219\n",
      "Train Epoch: 31 [90/399 (86%)]\tLoss: 0.016320\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 96/100 (96%)\n",
      "\n",
      "Train Epoch: 32 [0/399 (0%)]\tLoss: 0.009944\n",
      "Train Epoch: 32 [64/399 (14%)]\tLoss: 0.015326\n",
      "Train Epoch: 32 [128/399 (29%)]\tLoss: 0.014471\n",
      "Train Epoch: 32 [192/399 (43%)]\tLoss: 0.015902\n",
      "Train Epoch: 32 [256/399 (57%)]\tLoss: 0.027358\n",
      "Train Epoch: 32 [320/399 (71%)]\tLoss: 0.026219\n",
      "Train Epoch: 32 [90/399 (86%)]\tLoss: 0.010540\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 96/100 (96%)\n",
      "\n",
      "Train Epoch: 33 [0/399 (0%)]\tLoss: 0.007338\n",
      "Train Epoch: 33 [64/399 (14%)]\tLoss: 0.011414\n",
      "Train Epoch: 33 [128/399 (29%)]\tLoss: 0.045400\n",
      "Train Epoch: 33 [192/399 (43%)]\tLoss: 0.014168\n",
      "Train Epoch: 33 [256/399 (57%)]\tLoss: 0.005587\n",
      "Train Epoch: 33 [320/399 (71%)]\tLoss: 0.030688\n",
      "Train Epoch: 33 [90/399 (86%)]\tLoss: 0.010311\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 96/100 (96%)\n",
      "\n",
      "Train Epoch: 34 [0/399 (0%)]\tLoss: 0.028687\n",
      "Train Epoch: 34 [64/399 (14%)]\tLoss: 0.012251\n",
      "Train Epoch: 34 [128/399 (29%)]\tLoss: 0.012625\n",
      "Train Epoch: 34 [192/399 (43%)]\tLoss: 0.009644\n",
      "Train Epoch: 34 [256/399 (57%)]\tLoss: 0.007910\n",
      "Train Epoch: 34 [320/399 (71%)]\tLoss: 0.009166\n",
      "Train Epoch: 34 [90/399 (86%)]\tLoss: 0.012271\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 96/100 (96%)\n",
      "\n",
      "Train Epoch: 35 [0/399 (0%)]\tLoss: 0.008535\n",
      "Train Epoch: 35 [64/399 (14%)]\tLoss: 0.011740\n",
      "Train Epoch: 35 [128/399 (29%)]\tLoss: 0.013132\n",
      "Train Epoch: 35 [192/399 (43%)]\tLoss: 0.012086\n",
      "Train Epoch: 35 [256/399 (57%)]\tLoss: 0.014963\n",
      "Train Epoch: 35 [320/399 (71%)]\tLoss: 0.025016\n",
      "Train Epoch: 35 [90/399 (86%)]\tLoss: 0.017697\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 96/100 (96%)\n",
      "\n",
      "Train Epoch: 36 [0/399 (0%)]\tLoss: 0.014690\n",
      "Train Epoch: 36 [64/399 (14%)]\tLoss: 0.028599\n",
      "Train Epoch: 36 [128/399 (29%)]\tLoss: 0.010618\n",
      "Train Epoch: 36 [192/399 (43%)]\tLoss: 0.012108\n",
      "Train Epoch: 36 [256/399 (57%)]\tLoss: 0.007934\n",
      "Train Epoch: 36 [320/399 (71%)]\tLoss: 0.012153\n",
      "Train Epoch: 36 [90/399 (86%)]\tLoss: 0.005983\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 96/100 (96%)\n",
      "\n",
      "Train Epoch: 37 [0/399 (0%)]\tLoss: 0.006258\n",
      "Train Epoch: 37 [64/399 (14%)]\tLoss: 0.018387\n",
      "Train Epoch: 37 [128/399 (29%)]\tLoss: 0.009077\n",
      "Train Epoch: 37 [192/399 (43%)]\tLoss: 0.006029\n",
      "Train Epoch: 37 [256/399 (57%)]\tLoss: 0.011764\n",
      "Train Epoch: 37 [320/399 (71%)]\tLoss: 0.009915\n",
      "Train Epoch: 37 [90/399 (86%)]\tLoss: 0.046311\n",
      "\n",
      "Test set: Average loss: 0.0500, Accuracy: 95/100 (95%)\n",
      "\n",
      "Train Epoch: 38 [0/399 (0%)]\tLoss: 0.019465\n",
      "Train Epoch: 38 [64/399 (14%)]\tLoss: 0.014489\n",
      "Train Epoch: 38 [128/399 (29%)]\tLoss: 0.017927\n",
      "Train Epoch: 38 [192/399 (43%)]\tLoss: 0.029635\n",
      "Train Epoch: 38 [256/399 (57%)]\tLoss: 0.012101\n",
      "Train Epoch: 38 [320/399 (71%)]\tLoss: 0.007209\n",
      "Train Epoch: 38 [90/399 (86%)]\tLoss: 0.069262\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 96/100 (96%)\n",
      "\n",
      "Train Epoch: 39 [0/399 (0%)]\tLoss: 0.014188\n",
      "Train Epoch: 39 [64/399 (14%)]\tLoss: 0.010956\n",
      "Train Epoch: 39 [128/399 (29%)]\tLoss: 0.006912\n",
      "Train Epoch: 39 [192/399 (43%)]\tLoss: 0.013013\n",
      "Train Epoch: 39 [256/399 (57%)]\tLoss: 0.015946\n",
      "Train Epoch: 39 [320/399 (71%)]\tLoss: 0.013617\n",
      "Train Epoch: 39 [90/399 (86%)]\tLoss: 0.011589\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 96/100 (96%)\n",
      "\n",
      "Train Epoch: 40 [0/399 (0%)]\tLoss: 0.013873\n",
      "Train Epoch: 40 [64/399 (14%)]\tLoss: 0.004051\n",
      "Train Epoch: 40 [128/399 (29%)]\tLoss: 0.008345\n",
      "Train Epoch: 40 [192/399 (43%)]\tLoss: 0.014988\n",
      "Train Epoch: 40 [256/399 (57%)]\tLoss: 0.007980\n",
      "Train Epoch: 40 [320/399 (71%)]\tLoss: 0.013636\n",
      "Train Epoch: 40 [90/399 (86%)]\tLoss: 0.029734\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 96/100 (96%)\n",
      "\n",
      "Train Epoch: 41 [0/399 (0%)]\tLoss: 0.007883\n",
      "Train Epoch: 41 [64/399 (14%)]\tLoss: 0.022458\n",
      "Train Epoch: 41 [128/399 (29%)]\tLoss: 0.024112\n",
      "Train Epoch: 41 [192/399 (43%)]\tLoss: 0.004185\n",
      "Train Epoch: 41 [256/399 (57%)]\tLoss: 0.010885\n",
      "Train Epoch: 41 [320/399 (71%)]\tLoss: 0.027238\n",
      "Train Epoch: 41 [90/399 (86%)]\tLoss: 0.023032\n",
      "\n",
      "Test set: Average loss: 0.0600, Accuracy: 94/100 (94%)\n",
      "\n",
      "Train Epoch: 42 [0/399 (0%)]\tLoss: 0.007998\n",
      "Train Epoch: 42 [64/399 (14%)]\tLoss: 0.011932\n",
      "Train Epoch: 42 [128/399 (29%)]\tLoss: 0.006131\n",
      "Train Epoch: 42 [192/399 (43%)]\tLoss: 0.006907\n",
      "Train Epoch: 42 [256/399 (57%)]\tLoss: 0.030833\n",
      "Train Epoch: 42 [320/399 (71%)]\tLoss: 0.039650\n",
      "Train Epoch: 42 [90/399 (86%)]\tLoss: 0.026890\n",
      "\n",
      "Test set: Average loss: 0.0500, Accuracy: 95/100 (95%)\n",
      "\n",
      "Train Epoch: 43 [0/399 (0%)]\tLoss: 0.010265\n",
      "Train Epoch: 43 [64/399 (14%)]\tLoss: 0.012819\n",
      "Train Epoch: 43 [128/399 (29%)]\tLoss: 0.008462\n",
      "Train Epoch: 43 [192/399 (43%)]\tLoss: 0.009306\n",
      "Train Epoch: 43 [256/399 (57%)]\tLoss: 0.013598\n",
      "Train Epoch: 43 [320/399 (71%)]\tLoss: 0.009169\n",
      "Train Epoch: 43 [90/399 (86%)]\tLoss: 0.002615\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 96/100 (96%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 44 [0/399 (0%)]\tLoss: 0.014514\n",
      "Train Epoch: 44 [64/399 (14%)]\tLoss: 0.005701\n",
      "Train Epoch: 44 [128/399 (29%)]\tLoss: 0.011874\n",
      "Train Epoch: 44 [192/399 (43%)]\tLoss: 0.012709\n",
      "Train Epoch: 44 [256/399 (57%)]\tLoss: 0.024167\n",
      "Train Epoch: 44 [320/399 (71%)]\tLoss: 0.011285\n",
      "Train Epoch: 44 [90/399 (86%)]\tLoss: 0.032752\n",
      "\n",
      "Test set: Average loss: 0.0500, Accuracy: 95/100 (95%)\n",
      "\n",
      "Train Epoch: 45 [0/399 (0%)]\tLoss: 0.012828\n",
      "Train Epoch: 45 [64/399 (14%)]\tLoss: 0.007638\n",
      "Train Epoch: 45 [128/399 (29%)]\tLoss: 0.008891\n",
      "Train Epoch: 45 [192/399 (43%)]\tLoss: 0.006151\n",
      "Train Epoch: 45 [256/399 (57%)]\tLoss: 0.015825\n",
      "Train Epoch: 45 [320/399 (71%)]\tLoss: 0.012169\n",
      "Train Epoch: 45 [90/399 (86%)]\tLoss: 0.010101\n",
      "\n",
      "Test set: Average loss: 0.0500, Accuracy: 95/100 (95%)\n",
      "\n",
      "Train Epoch: 46 [0/399 (0%)]\tLoss: 0.014506\n",
      "Train Epoch: 46 [64/399 (14%)]\tLoss: 0.009413\n",
      "Train Epoch: 46 [128/399 (29%)]\tLoss: 0.003790\n",
      "Train Epoch: 46 [192/399 (43%)]\tLoss: 0.013778\n",
      "Train Epoch: 46 [256/399 (57%)]\tLoss: 0.014734\n",
      "Train Epoch: 46 [320/399 (71%)]\tLoss: 0.009413\n",
      "Train Epoch: 46 [90/399 (86%)]\tLoss: 0.009828\n",
      "\n",
      "Test set: Average loss: 0.0500, Accuracy: 95/100 (95%)\n",
      "\n",
      "Train Epoch: 47 [0/399 (0%)]\tLoss: 0.014942\n",
      "Train Epoch: 47 [64/399 (14%)]\tLoss: 0.004118\n",
      "Train Epoch: 47 [128/399 (29%)]\tLoss: 0.007274\n",
      "Train Epoch: 47 [192/399 (43%)]\tLoss: 0.004827\n",
      "Train Epoch: 47 [256/399 (57%)]\tLoss: 0.004433\n",
      "Train Epoch: 47 [320/399 (71%)]\tLoss: 0.008723\n",
      "Train Epoch: 47 [90/399 (86%)]\tLoss: 0.012191\n",
      "\n",
      "Test set: Average loss: 0.0500, Accuracy: 95/100 (95%)\n",
      "\n",
      "Train Epoch: 48 [0/399 (0%)]\tLoss: 0.007088\n",
      "Train Epoch: 48 [64/399 (14%)]\tLoss: 0.017865\n",
      "Train Epoch: 48 [128/399 (29%)]\tLoss: 0.004545\n",
      "Train Epoch: 48 [192/399 (43%)]\tLoss: 0.005544\n",
      "Train Epoch: 48 [256/399 (57%)]\tLoss: 0.002815\n",
      "Train Epoch: 48 [320/399 (71%)]\tLoss: 0.016761\n",
      "Train Epoch: 48 [90/399 (86%)]\tLoss: 0.003020\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 96/100 (96%)\n",
      "\n",
      "Train Epoch: 49 [0/399 (0%)]\tLoss: 0.002147\n",
      "Train Epoch: 49 [64/399 (14%)]\tLoss: 0.005079\n",
      "Train Epoch: 49 [128/399 (29%)]\tLoss: 0.006493\n",
      "Train Epoch: 49 [192/399 (43%)]\tLoss: 0.015795\n",
      "Train Epoch: 49 [256/399 (57%)]\tLoss: 0.013712\n",
      "Train Epoch: 49 [320/399 (71%)]\tLoss: 0.004238\n",
      "Train Epoch: 49 [90/399 (86%)]\tLoss: 0.002350\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 96/100 (96%)\n",
      "\n",
      "Train Epoch: 50 [0/399 (0%)]\tLoss: 0.002430\n",
      "Train Epoch: 50 [64/399 (14%)]\tLoss: 0.009368\n",
      "Train Epoch: 50 [128/399 (29%)]\tLoss: 0.006249\n",
      "Train Epoch: 50 [192/399 (43%)]\tLoss: 0.003113\n",
      "Train Epoch: 50 [256/399 (57%)]\tLoss: 0.016530\n",
      "Train Epoch: 50 [320/399 (71%)]\tLoss: 0.008354\n",
      "Train Epoch: 50 [90/399 (86%)]\tLoss: 0.025682\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 96/100 (96%)\n",
      "\n",
      "Train Epoch: 51 [0/399 (0%)]\tLoss: 0.002907\n",
      "Train Epoch: 51 [64/399 (14%)]\tLoss: 0.002536\n",
      "Train Epoch: 51 [128/399 (29%)]\tLoss: 0.007000\n",
      "Train Epoch: 51 [192/399 (43%)]\tLoss: 0.004977\n",
      "Train Epoch: 51 [256/399 (57%)]\tLoss: 0.004764\n",
      "Train Epoch: 51 [320/399 (71%)]\tLoss: 0.005096\n",
      "Train Epoch: 51 [90/399 (86%)]\tLoss: 0.008428\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 96/100 (96%)\n",
      "\n",
      "Train Epoch: 52 [0/399 (0%)]\tLoss: 0.007460\n",
      "Train Epoch: 52 [64/399 (14%)]\tLoss: 0.029834\n",
      "Train Epoch: 52 [128/399 (29%)]\tLoss: 0.002329\n",
      "Train Epoch: 52 [192/399 (43%)]\tLoss: 0.006697\n",
      "Train Epoch: 52 [256/399 (57%)]\tLoss: 0.004705\n",
      "Train Epoch: 52 [320/399 (71%)]\tLoss: 0.005577\n",
      "Train Epoch: 52 [90/399 (86%)]\tLoss: 0.005115\n",
      "\n",
      "Test set: Average loss: 0.0500, Accuracy: 95/100 (95%)\n",
      "\n",
      "Train Epoch: 53 [0/399 (0%)]\tLoss: 0.005589\n",
      "Train Epoch: 53 [64/399 (14%)]\tLoss: 0.008364\n",
      "Train Epoch: 53 [128/399 (29%)]\tLoss: 0.008060\n",
      "Train Epoch: 53 [192/399 (43%)]\tLoss: 0.004321\n",
      "Train Epoch: 53 [256/399 (57%)]\tLoss: 0.016093\n",
      "Train Epoch: 53 [320/399 (71%)]\tLoss: 0.004760\n",
      "Train Epoch: 53 [90/399 (86%)]\tLoss: 0.004387\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 96/100 (96%)\n",
      "\n",
      "Train Epoch: 54 [0/399 (0%)]\tLoss: 0.006125\n",
      "Train Epoch: 54 [64/399 (14%)]\tLoss: 0.002639\n",
      "Train Epoch: 54 [128/399 (29%)]\tLoss: 0.011539\n",
      "Train Epoch: 54 [192/399 (43%)]\tLoss: 0.008142\n",
      "Train Epoch: 54 [256/399 (57%)]\tLoss: 0.005276\n",
      "Train Epoch: 54 [320/399 (71%)]\tLoss: 0.014823\n",
      "Train Epoch: 54 [90/399 (86%)]\tLoss: 0.001740\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 96/100 (96%)\n",
      "\n",
      "Train Epoch: 55 [0/399 (0%)]\tLoss: 0.003599\n",
      "Train Epoch: 55 [64/399 (14%)]\tLoss: 0.001846\n",
      "Train Epoch: 55 [128/399 (29%)]\tLoss: 0.003841\n",
      "Train Epoch: 55 [192/399 (43%)]\tLoss: 0.004030\n",
      "Train Epoch: 55 [256/399 (57%)]\tLoss: 0.007720\n",
      "Train Epoch: 55 [320/399 (71%)]\tLoss: 0.006078\n",
      "Train Epoch: 55 [90/399 (86%)]\tLoss: 0.005249\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 96/100 (96%)\n",
      "\n",
      "Train Epoch: 56 [0/399 (0%)]\tLoss: 0.004002\n",
      "Train Epoch: 56 [64/399 (14%)]\tLoss: 0.004644\n",
      "Train Epoch: 56 [128/399 (29%)]\tLoss: 0.003019\n",
      "Train Epoch: 56 [192/399 (43%)]\tLoss: 0.005897\n",
      "Train Epoch: 56 [256/399 (57%)]\tLoss: 0.008811\n",
      "Train Epoch: 56 [320/399 (71%)]\tLoss: 0.002048\n",
      "Train Epoch: 56 [90/399 (86%)]\tLoss: 0.002530\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 96/100 (96%)\n",
      "\n",
      "Train Epoch: 57 [0/399 (0%)]\tLoss: 0.003989\n",
      "Train Epoch: 57 [64/399 (14%)]\tLoss: 0.005099\n",
      "Train Epoch: 57 [128/399 (29%)]\tLoss: 0.002054\n",
      "Train Epoch: 57 [192/399 (43%)]\tLoss: 0.006821\n",
      "Train Epoch: 57 [256/399 (57%)]\tLoss: 0.005973\n",
      "Train Epoch: 57 [320/399 (71%)]\tLoss: 0.004981\n",
      "Train Epoch: 57 [90/399 (86%)]\tLoss: 0.004311\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 96/100 (96%)\n",
      "\n",
      "Train Epoch: 58 [0/399 (0%)]\tLoss: 0.006125\n",
      "Train Epoch: 58 [64/399 (14%)]\tLoss: 0.030809\n",
      "Train Epoch: 58 [128/399 (29%)]\tLoss: 0.003260\n",
      "Train Epoch: 58 [192/399 (43%)]\tLoss: 0.003006\n",
      "Train Epoch: 58 [256/399 (57%)]\tLoss: 0.004637\n",
      "Train Epoch: 58 [320/399 (71%)]\tLoss: 0.002500\n",
      "Train Epoch: 58 [90/399 (86%)]\tLoss: 0.001009\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 96/100 (96%)\n",
      "\n",
      "Train Epoch: 59 [0/399 (0%)]\tLoss: 0.006299\n",
      "Train Epoch: 59 [64/399 (14%)]\tLoss: 0.004025\n",
      "Train Epoch: 59 [128/399 (29%)]\tLoss: 0.013095\n",
      "Train Epoch: 59 [192/399 (43%)]\tLoss: 0.002688\n",
      "Train Epoch: 59 [256/399 (57%)]\tLoss: 0.003400\n",
      "Train Epoch: 59 [320/399 (71%)]\tLoss: 0.002000\n",
      "Train Epoch: 59 [90/399 (86%)]\tLoss: 0.006362\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 96/100 (96%)\n",
      "\n",
      "Train Epoch: 60 [0/399 (0%)]\tLoss: 0.002648\n",
      "Train Epoch: 60 [64/399 (14%)]\tLoss: 0.004984\n",
      "Train Epoch: 60 [128/399 (29%)]\tLoss: 0.003187\n",
      "Train Epoch: 60 [192/399 (43%)]\tLoss: 0.001987\n",
      "Train Epoch: 60 [256/399 (57%)]\tLoss: 0.007331\n",
      "Train Epoch: 60 [320/399 (71%)]\tLoss: 0.006464\n",
      "Train Epoch: 60 [90/399 (86%)]\tLoss: 0.000966\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 96/100 (96%)\n",
      "\n",
      "Train Epoch: 61 [0/399 (0%)]\tLoss: 0.003953\n",
      "Train Epoch: 61 [64/399 (14%)]\tLoss: 0.002607\n",
      "Train Epoch: 61 [128/399 (29%)]\tLoss: 0.003440\n",
      "Train Epoch: 61 [192/399 (43%)]\tLoss: 0.002791\n",
      "Train Epoch: 61 [256/399 (57%)]\tLoss: 0.002929\n",
      "Train Epoch: 61 [320/399 (71%)]\tLoss: 0.001724\n",
      "Train Epoch: 61 [90/399 (86%)]\tLoss: 0.002966\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 96/100 (96%)\n",
      "\n",
      "Train Epoch: 62 [0/399 (0%)]\tLoss: 0.001692\n",
      "Train Epoch: 62 [64/399 (14%)]\tLoss: 0.002516\n",
      "Train Epoch: 62 [128/399 (29%)]\tLoss: 0.003033\n",
      "Train Epoch: 62 [192/399 (43%)]\tLoss: 0.003450\n",
      "Train Epoch: 62 [256/399 (57%)]\tLoss: 0.001961\n",
      "Train Epoch: 62 [320/399 (71%)]\tLoss: 0.006522\n",
      "Train Epoch: 62 [90/399 (86%)]\tLoss: 0.002904\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 96/100 (96%)\n",
      "\n",
      "Train Epoch: 63 [0/399 (0%)]\tLoss: 0.001129\n",
      "Train Epoch: 63 [64/399 (14%)]\tLoss: 0.004002\n",
      "Train Epoch: 63 [128/399 (29%)]\tLoss: 0.001953\n",
      "Train Epoch: 63 [192/399 (43%)]\tLoss: 0.005024\n",
      "Train Epoch: 63 [256/399 (57%)]\tLoss: 0.001543\n",
      "Train Epoch: 63 [320/399 (71%)]\tLoss: 0.002427\n",
      "Train Epoch: 63 [90/399 (86%)]\tLoss: 0.001235\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 96/100 (96%)\n",
      "\n",
      "Train Epoch: 64 [0/399 (0%)]\tLoss: 0.002544\n",
      "Train Epoch: 64 [64/399 (14%)]\tLoss: 0.004722\n",
      "Train Epoch: 64 [128/399 (29%)]\tLoss: 0.009243\n",
      "Train Epoch: 64 [192/399 (43%)]\tLoss: 0.004328\n",
      "Train Epoch: 64 [256/399 (57%)]\tLoss: 0.002021\n",
      "Train Epoch: 64 [320/399 (71%)]\tLoss: 0.003559\n",
      "Train Epoch: 64 [90/399 (86%)]\tLoss: 0.001267\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 96/100 (96%)\n",
      "\n",
      "Train Epoch: 65 [0/399 (0%)]\tLoss: 0.002452\n",
      "Train Epoch: 65 [64/399 (14%)]\tLoss: 0.008987\n",
      "Train Epoch: 65 [128/399 (29%)]\tLoss: 0.000952\n",
      "Train Epoch: 65 [192/399 (43%)]\tLoss: 0.001523\n",
      "Train Epoch: 65 [256/399 (57%)]\tLoss: 0.001977\n",
      "Train Epoch: 65 [320/399 (71%)]\tLoss: 0.001827\n",
      "Train Epoch: 65 [90/399 (86%)]\tLoss: 0.010863\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 96/100 (96%)\n",
      "\n",
      "Train Epoch: 66 [0/399 (0%)]\tLoss: 0.004951\n",
      "Train Epoch: 66 [64/399 (14%)]\tLoss: 0.009291\n",
      "Train Epoch: 66 [128/399 (29%)]\tLoss: 0.001365\n",
      "Train Epoch: 66 [192/399 (43%)]\tLoss: 0.005556\n",
      "Train Epoch: 66 [256/399 (57%)]\tLoss: 0.003264\n",
      "Train Epoch: 66 [320/399 (71%)]\tLoss: 0.003233\n",
      "Train Epoch: 66 [90/399 (86%)]\tLoss: 0.000991\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 96/100 (96%)\n",
      "\n",
      "Train Epoch: 67 [0/399 (0%)]\tLoss: 0.011741\n",
      "Train Epoch: 67 [64/399 (14%)]\tLoss: 0.003775\n",
      "Train Epoch: 67 [128/399 (29%)]\tLoss: 0.004465\n",
      "Train Epoch: 67 [192/399 (43%)]\tLoss: 0.002188\n",
      "Train Epoch: 67 [256/399 (57%)]\tLoss: 0.007043\n",
      "Train Epoch: 67 [320/399 (71%)]\tLoss: 0.004202\n",
      "Train Epoch: 67 [90/399 (86%)]\tLoss: 0.000368\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 96/100 (96%)\n",
      "\n",
      "Train Epoch: 68 [0/399 (0%)]\tLoss: 0.003669\n",
      "Train Epoch: 68 [64/399 (14%)]\tLoss: 0.002638\n",
      "Train Epoch: 68 [128/399 (29%)]\tLoss: 0.003103\n",
      "Train Epoch: 68 [192/399 (43%)]\tLoss: 0.003198\n",
      "Train Epoch: 68 [256/399 (57%)]\tLoss: 0.005081\n",
      "Train Epoch: 68 [320/399 (71%)]\tLoss: 0.002906\n",
      "Train Epoch: 68 [90/399 (86%)]\tLoss: 0.001643\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 96/100 (96%)\n",
      "\n",
      "Train Epoch: 69 [0/399 (0%)]\tLoss: 0.002715\n",
      "Train Epoch: 69 [64/399 (14%)]\tLoss: 0.003312\n",
      "Train Epoch: 69 [128/399 (29%)]\tLoss: 0.004100\n",
      "Train Epoch: 69 [192/399 (43%)]\tLoss: 0.003131\n",
      "Train Epoch: 69 [256/399 (57%)]\tLoss: 0.002455\n",
      "Train Epoch: 69 [320/399 (71%)]\tLoss: 0.000873\n",
      "Train Epoch: 69 [90/399 (86%)]\tLoss: 0.003271\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 96/100 (96%)\n",
      "\n",
      "Train Epoch: 70 [0/399 (0%)]\tLoss: 0.009252\n",
      "Train Epoch: 70 [64/399 (14%)]\tLoss: 0.002445\n",
      "Train Epoch: 70 [128/399 (29%)]\tLoss: 0.010921\n",
      "Train Epoch: 70 [192/399 (43%)]\tLoss: 0.001329\n",
      "Train Epoch: 70 [256/399 (57%)]\tLoss: 0.002617\n",
      "Train Epoch: 70 [320/399 (71%)]\tLoss: 0.002106\n",
      "Train Epoch: 70 [90/399 (86%)]\tLoss: 0.001745\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 96/100 (96%)\n",
      "\n",
      "Train Epoch: 71 [0/399 (0%)]\tLoss: 0.003234\n",
      "Train Epoch: 71 [64/399 (14%)]\tLoss: 0.004404\n",
      "Train Epoch: 71 [128/399 (29%)]\tLoss: 0.006096\n",
      "Train Epoch: 71 [192/399 (43%)]\tLoss: 0.002629\n",
      "Train Epoch: 71 [256/399 (57%)]\tLoss: 0.004782\n",
      "Train Epoch: 71 [320/399 (71%)]\tLoss: 0.001464\n",
      "Train Epoch: 71 [90/399 (86%)]\tLoss: 0.002037\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 96/100 (96%)\n",
      "\n",
      "Train Epoch: 72 [0/399 (0%)]\tLoss: 0.001598\n",
      "Train Epoch: 72 [64/399 (14%)]\tLoss: 0.000609\n",
      "Train Epoch: 72 [128/399 (29%)]\tLoss: 0.001334\n",
      "Train Epoch: 72 [192/399 (43%)]\tLoss: 0.003667\n",
      "Train Epoch: 72 [256/399 (57%)]\tLoss: 0.004080\n",
      "Train Epoch: 72 [320/399 (71%)]\tLoss: 0.006397\n",
      "Train Epoch: 72 [90/399 (86%)]\tLoss: 0.014000\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 96/100 (96%)\n",
      "\n",
      "Train Epoch: 73 [0/399 (0%)]\tLoss: 0.016262\n",
      "Train Epoch: 73 [64/399 (14%)]\tLoss: 0.001271\n",
      "Train Epoch: 73 [128/399 (29%)]\tLoss: 0.003837\n",
      "Train Epoch: 73 [192/399 (43%)]\tLoss: 0.004340\n",
      "Train Epoch: 73 [256/399 (57%)]\tLoss: 0.005787\n",
      "Train Epoch: 73 [320/399 (71%)]\tLoss: 0.008217\n",
      "Train Epoch: 73 [90/399 (86%)]\tLoss: 0.003200\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 96/100 (96%)\n",
      "\n",
      "Train Epoch: 74 [0/399 (0%)]\tLoss: 0.002357\n",
      "Train Epoch: 74 [64/399 (14%)]\tLoss: 0.005073\n",
      "Train Epoch: 74 [128/399 (29%)]\tLoss: 0.006270\n",
      "Train Epoch: 74 [192/399 (43%)]\tLoss: 0.006258\n",
      "Train Epoch: 74 [256/399 (57%)]\tLoss: 0.001868\n",
      "Train Epoch: 74 [320/399 (71%)]\tLoss: 0.003556\n",
      "Train Epoch: 74 [90/399 (86%)]\tLoss: 0.002442\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 96/100 (96%)\n",
      "\n",
      "Train Epoch: 75 [0/399 (0%)]\tLoss: 0.002409\n",
      "Train Epoch: 75 [64/399 (14%)]\tLoss: 0.002562\n",
      "Train Epoch: 75 [128/399 (29%)]\tLoss: 0.005258\n",
      "Train Epoch: 75 [192/399 (43%)]\tLoss: 0.003736\n",
      "Train Epoch: 75 [256/399 (57%)]\tLoss: 0.003604\n",
      "Train Epoch: 75 [320/399 (71%)]\tLoss: 0.002815\n",
      "Train Epoch: 75 [90/399 (86%)]\tLoss: 0.005092\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 96/100 (96%)\n",
      "\n",
      "Train Epoch: 76 [0/399 (0%)]\tLoss: 0.002790\n",
      "Train Epoch: 76 [64/399 (14%)]\tLoss: 0.001988\n",
      "Train Epoch: 76 [128/399 (29%)]\tLoss: 0.004710\n",
      "Train Epoch: 76 [192/399 (43%)]\tLoss: 0.003421\n",
      "Train Epoch: 76 [256/399 (57%)]\tLoss: 0.001806\n",
      "Train Epoch: 76 [320/399 (71%)]\tLoss: 0.001344\n",
      "Train Epoch: 76 [90/399 (86%)]\tLoss: 0.007031\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 96/100 (96%)\n",
      "\n",
      "Train Epoch: 77 [0/399 (0%)]\tLoss: 0.002074\n",
      "Train Epoch: 77 [64/399 (14%)]\tLoss: 0.004519\n",
      "Train Epoch: 77 [128/399 (29%)]\tLoss: 0.005820\n",
      "Train Epoch: 77 [192/399 (43%)]\tLoss: 0.002026\n",
      "Train Epoch: 77 [256/399 (57%)]\tLoss: 0.000936\n",
      "Train Epoch: 77 [320/399 (71%)]\tLoss: 0.005156\n",
      "Train Epoch: 77 [90/399 (86%)]\tLoss: 0.002192\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 96/100 (96%)\n",
      "\n",
      "Train Epoch: 78 [0/399 (0%)]\tLoss: 0.008654\n",
      "Train Epoch: 78 [64/399 (14%)]\tLoss: 0.000857\n",
      "Train Epoch: 78 [128/399 (29%)]\tLoss: 0.002216\n",
      "Train Epoch: 78 [192/399 (43%)]\tLoss: 0.001598\n",
      "Train Epoch: 78 [256/399 (57%)]\tLoss: 0.002837\n",
      "Train Epoch: 78 [320/399 (71%)]\tLoss: 0.005524\n",
      "Train Epoch: 78 [90/399 (86%)]\tLoss: 0.000704\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 96/100 (96%)\n",
      "\n",
      "Train Epoch: 79 [0/399 (0%)]\tLoss: 0.002691\n",
      "Train Epoch: 79 [64/399 (14%)]\tLoss: 0.003301\n",
      "Train Epoch: 79 [128/399 (29%)]\tLoss: 0.000448\n",
      "Train Epoch: 79 [192/399 (43%)]\tLoss: 0.001707\n",
      "Train Epoch: 79 [256/399 (57%)]\tLoss: 0.000983\n",
      "Train Epoch: 79 [320/399 (71%)]\tLoss: 0.001227\n",
      "Train Epoch: 79 [90/399 (86%)]\tLoss: 0.007409\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 96/100 (96%)\n",
      "\n",
      "Train Epoch: 80 [0/399 (0%)]\tLoss: 0.002896\n",
      "Train Epoch: 80 [64/399 (14%)]\tLoss: 0.001751\n",
      "Train Epoch: 80 [128/399 (29%)]\tLoss: 0.003787\n",
      "Train Epoch: 80 [192/399 (43%)]\tLoss: 0.003050\n",
      "Train Epoch: 80 [256/399 (57%)]\tLoss: 0.002756\n",
      "Train Epoch: 80 [320/399 (71%)]\tLoss: 0.004798\n",
      "Train Epoch: 80 [90/399 (86%)]\tLoss: 0.001451\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 96/100 (96%)\n",
      "\n",
      "Train Epoch: 81 [0/399 (0%)]\tLoss: 0.001394\n",
      "Train Epoch: 81 [64/399 (14%)]\tLoss: 0.004903\n",
      "Train Epoch: 81 [128/399 (29%)]\tLoss: 0.001921\n",
      "Train Epoch: 81 [192/399 (43%)]\tLoss: 0.001148\n",
      "Train Epoch: 81 [256/399 (57%)]\tLoss: 0.005253\n",
      "Train Epoch: 81 [320/399 (71%)]\tLoss: 0.003413\n",
      "Train Epoch: 81 [90/399 (86%)]\tLoss: 0.000705\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 96/100 (96%)\n",
      "\n",
      "Train Epoch: 82 [0/399 (0%)]\tLoss: 0.001437\n",
      "Train Epoch: 82 [64/399 (14%)]\tLoss: 0.002024\n",
      "Train Epoch: 82 [128/399 (29%)]\tLoss: 0.001436\n",
      "Train Epoch: 82 [192/399 (43%)]\tLoss: 0.002025\n",
      "Train Epoch: 82 [256/399 (57%)]\tLoss: 0.002421\n",
      "Train Epoch: 82 [320/399 (71%)]\tLoss: 0.001170\n",
      "Train Epoch: 82 [90/399 (86%)]\tLoss: 0.000489\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 96/100 (96%)\n",
      "\n",
      "Train Epoch: 83 [0/399 (0%)]\tLoss: 0.002095\n",
      "Train Epoch: 83 [64/399 (14%)]\tLoss: 0.000688\n",
      "Train Epoch: 83 [128/399 (29%)]\tLoss: 0.003381\n",
      "Train Epoch: 83 [192/399 (43%)]\tLoss: 0.001233\n",
      "Train Epoch: 83 [256/399 (57%)]\tLoss: 0.001333\n",
      "Train Epoch: 83 [320/399 (71%)]\tLoss: 0.003362\n",
      "Train Epoch: 83 [90/399 (86%)]\tLoss: 0.004037\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 96/100 (96%)\n",
      "\n",
      "Train Epoch: 84 [0/399 (0%)]\tLoss: 0.001759\n",
      "Train Epoch: 84 [64/399 (14%)]\tLoss: 0.001058\n",
      "Train Epoch: 84 [128/399 (29%)]\tLoss: 0.002539\n",
      "Train Epoch: 84 [192/399 (43%)]\tLoss: 0.002780\n",
      "Train Epoch: 84 [256/399 (57%)]\tLoss: 0.002531\n",
      "Train Epoch: 84 [320/399 (71%)]\tLoss: 0.000994\n",
      "Train Epoch: 84 [90/399 (86%)]\tLoss: 0.000742\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 96/100 (96%)\n",
      "\n",
      "Train Epoch: 85 [0/399 (0%)]\tLoss: 0.002489\n",
      "Train Epoch: 85 [64/399 (14%)]\tLoss: 0.001312\n",
      "Train Epoch: 85 [128/399 (29%)]\tLoss: 0.004419\n",
      "Train Epoch: 85 [192/399 (43%)]\tLoss: 0.001624\n",
      "Train Epoch: 85 [256/399 (57%)]\tLoss: 0.002631\n",
      "Train Epoch: 85 [320/399 (71%)]\tLoss: 0.001363\n",
      "Train Epoch: 85 [90/399 (86%)]\tLoss: 0.000704\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 96/100 (96%)\n",
      "\n",
      "Train Epoch: 86 [0/399 (0%)]\tLoss: 0.001197\n",
      "Train Epoch: 86 [64/399 (14%)]\tLoss: 0.001303\n",
      "Train Epoch: 86 [128/399 (29%)]\tLoss: 0.001133\n",
      "Train Epoch: 86 [192/399 (43%)]\tLoss: 0.000737\n",
      "Train Epoch: 86 [256/399 (57%)]\tLoss: 0.001592\n",
      "Train Epoch: 86 [320/399 (71%)]\tLoss: 0.001138\n",
      "Train Epoch: 86 [90/399 (86%)]\tLoss: 0.000986\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 96/100 (96%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch: 87 [0/399 (0%)]\tLoss: 0.002033\n",
      "Train Epoch: 87 [64/399 (14%)]\tLoss: 0.001287\n",
      "Train Epoch: 87 [128/399 (29%)]\tLoss: 0.002986\n",
      "Train Epoch: 87 [192/399 (43%)]\tLoss: 0.000966\n",
      "Train Epoch: 87 [256/399 (57%)]\tLoss: 0.001482\n",
      "Train Epoch: 87 [320/399 (71%)]\tLoss: 0.000871\n",
      "Train Epoch: 87 [90/399 (86%)]\tLoss: 0.001254\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 96/100 (96%)\n",
      "\n",
      "Train Epoch: 88 [0/399 (0%)]\tLoss: 0.001904\n",
      "Train Epoch: 88 [64/399 (14%)]\tLoss: 0.000884\n",
      "Train Epoch: 88 [128/399 (29%)]\tLoss: 0.001096\n",
      "Train Epoch: 88 [192/399 (43%)]\tLoss: 0.001741\n",
      "Train Epoch: 88 [256/399 (57%)]\tLoss: 0.001676\n",
      "Train Epoch: 88 [320/399 (71%)]\tLoss: 0.000704\n",
      "Train Epoch: 88 [90/399 (86%)]\tLoss: 0.001981\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 96/100 (96%)\n",
      "\n",
      "Train Epoch: 89 [0/399 (0%)]\tLoss: 0.001161\n",
      "Train Epoch: 89 [64/399 (14%)]\tLoss: 0.000253\n",
      "Train Epoch: 89 [128/399 (29%)]\tLoss: 0.001251\n",
      "Train Epoch: 89 [192/399 (43%)]\tLoss: 0.000889\n",
      "Train Epoch: 89 [256/399 (57%)]\tLoss: 0.002225\n",
      "Train Epoch: 89 [320/399 (71%)]\tLoss: 0.001654\n",
      "Train Epoch: 89 [90/399 (86%)]\tLoss: 0.006236\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 96/100 (96%)\n",
      "\n",
      "Train Epoch: 90 [0/399 (0%)]\tLoss: 0.005020\n",
      "Train Epoch: 90 [64/399 (14%)]\tLoss: 0.000337\n",
      "Train Epoch: 90 [128/399 (29%)]\tLoss: 0.000874\n",
      "Train Epoch: 90 [192/399 (43%)]\tLoss: 0.000848\n",
      "Train Epoch: 90 [256/399 (57%)]\tLoss: 0.000770\n",
      "Train Epoch: 90 [320/399 (71%)]\tLoss: 0.000675\n",
      "Train Epoch: 90 [90/399 (86%)]\tLoss: 0.001541\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 96/100 (96%)\n",
      "\n",
      "Train Epoch: 91 [0/399 (0%)]\tLoss: 0.000707\n",
      "Train Epoch: 91 [64/399 (14%)]\tLoss: 0.002778\n",
      "Train Epoch: 91 [128/399 (29%)]\tLoss: 0.001307\n",
      "Train Epoch: 91 [192/399 (43%)]\tLoss: 0.000477\n",
      "Train Epoch: 91 [256/399 (57%)]\tLoss: 0.001526\n",
      "Train Epoch: 91 [320/399 (71%)]\tLoss: 0.004287\n",
      "Train Epoch: 91 [90/399 (86%)]\tLoss: 0.001974\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 96/100 (96%)\n",
      "\n",
      "Train Epoch: 92 [0/399 (0%)]\tLoss: 0.001924\n",
      "Train Epoch: 92 [64/399 (14%)]\tLoss: 0.001633\n",
      "Train Epoch: 92 [128/399 (29%)]\tLoss: 0.001685\n",
      "Train Epoch: 92 [192/399 (43%)]\tLoss: 0.001128\n",
      "Train Epoch: 92 [256/399 (57%)]\tLoss: 0.002957\n",
      "Train Epoch: 92 [320/399 (71%)]\tLoss: 0.000939\n",
      "Train Epoch: 92 [90/399 (86%)]\tLoss: 0.008012\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 96/100 (96%)\n",
      "\n",
      "Train Epoch: 93 [0/399 (0%)]\tLoss: 0.002487\n",
      "Train Epoch: 93 [64/399 (14%)]\tLoss: 0.004659\n",
      "Train Epoch: 93 [128/399 (29%)]\tLoss: 0.005243\n",
      "Train Epoch: 93 [192/399 (43%)]\tLoss: 0.001220\n",
      "Train Epoch: 93 [256/399 (57%)]\tLoss: 0.002413\n",
      "Train Epoch: 93 [320/399 (71%)]\tLoss: 0.001081\n",
      "Train Epoch: 93 [90/399 (86%)]\tLoss: 0.002389\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 96/100 (96%)\n",
      "\n",
      "Train Epoch: 94 [0/399 (0%)]\tLoss: 0.001215\n",
      "Train Epoch: 94 [64/399 (14%)]\tLoss: 0.001086\n",
      "Train Epoch: 94 [128/399 (29%)]\tLoss: 0.001883\n",
      "Train Epoch: 94 [192/399 (43%)]\tLoss: 0.001888\n",
      "Train Epoch: 94 [256/399 (57%)]\tLoss: 0.000752\n",
      "Train Epoch: 94 [320/399 (71%)]\tLoss: 0.001460\n",
      "Train Epoch: 94 [90/399 (86%)]\tLoss: 0.001688\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 96/100 (96%)\n",
      "\n",
      "Train Epoch: 95 [0/399 (0%)]\tLoss: 0.000643\n",
      "Train Epoch: 95 [64/399 (14%)]\tLoss: 0.003166\n",
      "Train Epoch: 95 [128/399 (29%)]\tLoss: 0.001328\n",
      "Train Epoch: 95 [192/399 (43%)]\tLoss: 0.001071\n",
      "Train Epoch: 95 [256/399 (57%)]\tLoss: 0.001100\n",
      "Train Epoch: 95 [320/399 (71%)]\tLoss: 0.002229\n",
      "Train Epoch: 95 [90/399 (86%)]\tLoss: 0.000898\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 96/100 (96%)\n",
      "\n",
      "Train Epoch: 96 [0/399 (0%)]\tLoss: 0.002467\n",
      "Train Epoch: 96 [64/399 (14%)]\tLoss: 0.004126\n",
      "Train Epoch: 96 [128/399 (29%)]\tLoss: 0.001101\n",
      "Train Epoch: 96 [192/399 (43%)]\tLoss: 0.002262\n",
      "Train Epoch: 96 [256/399 (57%)]\tLoss: 0.001196\n",
      "Train Epoch: 96 [320/399 (71%)]\tLoss: 0.001774\n",
      "Train Epoch: 96 [90/399 (86%)]\tLoss: 0.001172\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 96/100 (96%)\n",
      "\n",
      "Train Epoch: 97 [0/399 (0%)]\tLoss: 0.001442\n",
      "Train Epoch: 97 [64/399 (14%)]\tLoss: 0.004021\n",
      "Train Epoch: 97 [128/399 (29%)]\tLoss: 0.001178\n",
      "Train Epoch: 97 [192/399 (43%)]\tLoss: 0.000505\n",
      "Train Epoch: 97 [256/399 (57%)]\tLoss: 0.001143\n",
      "Train Epoch: 97 [320/399 (71%)]\tLoss: 0.000870\n",
      "Train Epoch: 97 [90/399 (86%)]\tLoss: 0.002338\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 96/100 (96%)\n",
      "\n",
      "Train Epoch: 98 [0/399 (0%)]\tLoss: 0.000503\n",
      "Train Epoch: 98 [64/399 (14%)]\tLoss: 0.001034\n",
      "Train Epoch: 98 [128/399 (29%)]\tLoss: 0.001114\n",
      "Train Epoch: 98 [192/399 (43%)]\tLoss: 0.002219\n",
      "Train Epoch: 98 [256/399 (57%)]\tLoss: 0.003488\n",
      "Train Epoch: 98 [320/399 (71%)]\tLoss: 0.002477\n",
      "Train Epoch: 98 [90/399 (86%)]\tLoss: 0.001409\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 96/100 (96%)\n",
      "\n",
      "Train Epoch: 99 [0/399 (0%)]\tLoss: 0.000804\n",
      "Train Epoch: 99 [64/399 (14%)]\tLoss: 0.000750\n",
      "Train Epoch: 99 [128/399 (29%)]\tLoss: 0.000404\n",
      "Train Epoch: 99 [192/399 (43%)]\tLoss: 0.001218\n",
      "Train Epoch: 99 [256/399 (57%)]\tLoss: 0.002140\n",
      "Train Epoch: 99 [320/399 (71%)]\tLoss: 0.001374\n",
      "Train Epoch: 99 [90/399 (86%)]\tLoss: 0.000052\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 96/100 (96%)\n",
      "\n",
      "Train Epoch: 100 [0/399 (0%)]\tLoss: 0.001300\n",
      "Train Epoch: 100 [64/399 (14%)]\tLoss: 0.001070\n",
      "Train Epoch: 100 [128/399 (29%)]\tLoss: 0.001526\n",
      "Train Epoch: 100 [192/399 (43%)]\tLoss: 0.001294\n",
      "Train Epoch: 100 [256/399 (57%)]\tLoss: 0.000672\n",
      "Train Epoch: 100 [320/399 (71%)]\tLoss: 0.000645\n",
      "Train Epoch: 100 [90/399 (86%)]\tLoss: 0.000408\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 96/100 (96%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import optuna\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "BATCHSIZE = 64\n",
    "\n",
    "optuna.logging.disable_default_handler()\n",
    "\n",
    "\n",
    "class MyDataSet(Dataset):\n",
    "    def __init__(self, csv_path, root_dir):\n",
    "        self.image_dataframe = pd.read_csv(csv_path)\n",
    "        self.root_dir = root_dir\n",
    "        self.images = os.listdir(self.root_dir)\n",
    "        self.transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 画像読み込み\n",
    "        image_name = self.images[idx]\n",
    "        image = Image.open(os.path.join(self.root_dir, image_name))\n",
    "        image = image.convert('RGB')  # PyTorch 0.4以降\n",
    "        # label (0 or 1)\n",
    "        label = self.image_dataframe.query('ImageName==\"' + image_name + '\"')['ImageLabel'].iloc[0]\n",
    "        return self.transform(image), int(label)\n",
    "\n",
    "\n",
    "imgDataset = MyDataSet('/home/naoki/Documents/newgame.csv', '/home/naoki/Pictures/anime_face/newgame!!/data/')\n",
    "\n",
    "train_data, test_data = train_test_split(imgDataset, test_size=0.2)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True, num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=64, shuffle=True, num_workers=4)\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.activation = F.elu\n",
    "        # self.activation = trial.suggest_categorical('activation', [F.relu, F.elu])\n",
    "        self.conv1 = nn.Conv2d(3, 30, kernel_size=5)  # 64*64*3 -> 60*60*30\n",
    "        self.conv2 = nn.Conv2d(30, 60, kernel_size=5)  # 30*30*30 -> 26*26*60\n",
    "        self.conv2_drop = nn.Dropout2d(p=0.345478067932839)  # 0〜0.8の間でサンプリング\n",
    "        self.fc1 = nn.Linear(13 * 13 * 60, 150)\n",
    "        self.fc2 = nn.Linear(150, 6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = self.activation(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 13 * 13 * 60)\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "def train(epoch, model, device, train_loader, optimizer):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "            epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                   100. * batch_idx / len(train_loader), loss.data[0]))\n",
    "\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():  # 計算グラフを作らない\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        1 - correct / len(test_loader.dataset), correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = Net().to(device)\n",
    "print(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0002900399340813237, weight_decay=1.4248031080514087e-06)\n",
    "\n",
    "for epoch in range(1, 100 + 1):\n",
    "    train(epoch, model, device, train_loader, optimizer)\n",
    "    test(model, device, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def test_final(model, device, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    name_list = [\"aoba\", \"hajime\", \"hihumi\", \"kou\", \"rin\", \"yun\"]\n",
    "    transform = transforms.Compose([transforms.ToPILImage()])\n",
    "    with torch.no_grad():  # 計算グラフを作らない\n",
    "        for data, target in test_loader:\n",
    "            data_org = copy.deepcopy(data)\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            \n",
    "            for i in range(data.size()[0]):\n",
    "                image = transform(data_org[i])\n",
    "                image.show()\n",
    "                time.sleep(3)\n",
    "                print(\"target : {}\".format(name_list[target[i]]))\n",
    "                print(\"pred : {}\".format(name_list[pred[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target : hihumi\n",
      "pred : hihumi\n",
      "target : kou\n",
      "pred : kou\n",
      "target : yun\n",
      "pred : yun\n",
      "target : hajime\n",
      "pred : hajime\n",
      "target : aoba\n",
      "pred : aoba\n",
      "target : hihumi\n",
      "pred : hihumi\n",
      "target : rin\n",
      "pred : rin\n",
      "target : yun\n",
      "pred : yun\n",
      "target : kou\n",
      "pred : kou\n",
      "target : aoba\n",
      "pred : aoba\n",
      "target : aoba\n",
      "pred : aoba\n",
      "target : aoba\n",
      "pred : aoba\n",
      "target : hihumi\n",
      "pred : rin\n",
      "target : aoba\n",
      "pred : aoba\n",
      "target : hihumi\n",
      "pred : hajime\n",
      "target : aoba\n",
      "pred : aoba\n",
      "target : yun\n",
      "pred : yun\n",
      "target : aoba\n",
      "pred : aoba\n",
      "target : kou\n",
      "pred : kou\n",
      "target : aoba\n",
      "pred : aoba\n",
      "target : hihumi\n",
      "pred : hihumi\n",
      "target : rin\n",
      "pred : rin\n",
      "target : rin\n",
      "pred : rin\n",
      "target : aoba\n",
      "pred : aoba\n",
      "target : aoba\n",
      "pred : aoba\n",
      "target : yun\n",
      "pred : yun\n",
      "target : kou\n",
      "pred : kou\n",
      "target : hajime\n",
      "pred : hajime\n",
      "target : yun\n",
      "pred : yun\n",
      "target : aoba\n",
      "pred : aoba\n",
      "target : yun\n",
      "pred : yun\n",
      "target : hajime\n",
      "pred : hajime\n",
      "target : aoba\n",
      "pred : aoba\n",
      "target : aoba\n",
      "pred : aoba\n",
      "target : rin\n",
      "pred : rin\n",
      "target : kou\n",
      "pred : kou\n",
      "target : yun\n",
      "pred : yun\n",
      "target : aoba\n",
      "pred : aoba\n",
      "target : yun\n",
      "pred : yun\n",
      "target : hajime\n",
      "pred : hajime\n",
      "target : rin\n",
      "pred : rin\n",
      "target : yun\n",
      "pred : yun\n",
      "target : aoba\n",
      "pred : aoba\n",
      "target : rin\n",
      "pred : rin\n",
      "target : kou\n",
      "pred : kou\n",
      "target : hajime\n",
      "pred : hajime\n",
      "target : yun\n",
      "pred : yun\n",
      "target : yun\n",
      "pred : kou\n",
      "target : hajime\n",
      "pred : hajime\n",
      "target : hajime\n",
      "pred : hajime\n",
      "target : hihumi\n",
      "pred : hihumi\n",
      "target : yun\n",
      "pred : yun\n",
      "target : yun\n",
      "pred : yun\n",
      "target : kou\n",
      "pred : kou\n",
      "target : aoba\n",
      "pred : aoba\n",
      "target : hajime\n",
      "pred : hajime\n",
      "target : hajime\n",
      "pred : hajime\n",
      "target : rin\n",
      "pred : rin\n",
      "target : aoba\n",
      "pred : aoba\n",
      "target : kou\n",
      "pred : kou\n",
      "target : rin\n",
      "pred : rin\n",
      "target : hihumi\n",
      "pred : hihumi\n",
      "target : hihumi\n",
      "pred : hihumi\n",
      "target : kou\n",
      "pred : kou\n",
      "target : kou\n",
      "pred : kou\n",
      "target : kou\n",
      "pred : kou\n",
      "target : aoba\n",
      "pred : aoba\n",
      "target : hajime\n",
      "pred : hajime\n",
      "target : aoba\n",
      "pred : aoba\n",
      "target : hihumi\n",
      "pred : hihumi\n",
      "target : aoba\n",
      "pred : aoba\n",
      "target : aoba\n",
      "pred : aoba\n",
      "target : rin\n",
      "pred : rin\n",
      "target : yun\n",
      "pred : yun\n",
      "target : yun\n",
      "pred : kou\n",
      "target : rin\n",
      "pred : rin\n",
      "target : rin\n",
      "pred : rin\n",
      "target : hihumi\n",
      "pred : hihumi\n",
      "target : hihumi\n",
      "pred : hihumi\n",
      "target : aoba\n",
      "pred : aoba\n",
      "target : yun\n",
      "pred : yun\n",
      "target : aoba\n",
      "pred : aoba\n",
      "target : kou\n",
      "pred : kou\n",
      "target : rin\n",
      "pred : rin\n",
      "target : rin\n",
      "pred : rin\n",
      "target : rin\n",
      "pred : rin\n",
      "target : aoba\n",
      "pred : aoba\n",
      "target : aoba\n",
      "pred : aoba\n",
      "target : yun\n",
      "pred : yun\n",
      "target : hajime\n",
      "pred : hajime\n",
      "target : aoba\n",
      "pred : aoba\n",
      "target : hihumi\n",
      "pred : hihumi\n",
      "target : kou\n",
      "pred : kou\n",
      "target : rin\n",
      "pred : rin\n",
      "target : hajime\n",
      "pred : hajime\n",
      "target : rin\n",
      "pred : rin\n",
      "target : aoba\n",
      "pred : aoba\n",
      "target : aoba\n",
      "pred : aoba\n",
      "target : aoba\n",
      "pred : aoba\n",
      "target : aoba\n",
      "pred : aoba\n"
     ]
    }
   ],
   "source": [
    "test_final(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name = \"example\"\n",
    "image = Image.open(\"/home/naoki/Pictures/anime_movie/newgame!!/41.png\")\n",
    "image = image.convert('RGB')\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "image.size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3-TensorFlow",
   "language": "python",
   "name": "py35_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
